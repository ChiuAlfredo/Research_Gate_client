title,link,question_date,question_abstract,answer_content,has_more_answers,created_at,updated_at,trackid
Which software is good to handle database setup from the beginning?,https://www.researchgate.net/post/Which_software_is_good_to_handle_database_setup_from_the_beginning?_sg=imw6dC5peIGouiE3zkJX0wlTdXkcToVr65xXbZWvvP8q3qx-bxasIkm4RjYgLp_Ek4iNgrj7H7FT04Q,2014-04-01 00:00:00,"I need to set up a database with the following requirements:,,- easy handling (data entry, read out / statistics, changing the data entry interface and adding new parameters),,- in best case it should be web based --> the db file is on a server in our network and can be accessed (for data entry) by a web browser,,What do you recommend? Filemaker or MS Access, or any other solutions?,","MYSQL with phpmyadmin best bet is LAMPP stack. | MYSQL database. You can administrate it with phpmyadmin. It is easy to manage. | Yes, I agree with both of them. PHPmyadmin is the best to administrate a database for beginners (it is not command line). Give it a try! There are many many tutorials around! | Other solution, the best:MySQL database with web based administration (PHPmyadmin or SQLbuddy). | XAMPP package is good choice also. | If you have to build everything from the beginning and if it's web based - Firstly you have to design database (E/R model for example), to define the tables, after that to define primary keys, foreign keys and references between the tables inside the database, to create tables and relations with SQL commands and in the end to start entering data and make requests after that.",False,2025-01-20 01:04:22.112870,2025-01-20 01:04:22.112870,4bd0c214d68711ef89b40c9a3cb15cde
Can you give examples of software for using Object Oriented Database Management Systems?,https://www.researchgate.net/post/Can_you_give_examples_of_software_for_using_Object_Oriented_Database_Management_Systems?_sg=jTIM-QqiHoAiSjAHr1tun_OmRrar2ho-5sXMy04D36FbC8dIBdtv_das4WpuL0UrMzmNNz9vgbozEyk,2015-01-01 00:00:00,Microsoft access is a software example for relational databases. I need more examples for relational databases. I need also some more examples for Object oriented databases and XML databases.,"Caché, ConceptBase, Db4o, GemStone/S, NeoDatis ODB, ObjectDatabase++, ObjectDB, Objectivity/DB, ObjectStore, ODABA, OpenAccess, OpenLink Virtuoso, Perst, Picolisp, siaqodb, Twig, Versant Object Database, WakandaDB, Zope Object Database. | From stone age: OBST (unmaintained open source, will not compile, I guess) & Ontos (probably changed name). | Oracle | BaseX is an example for XML database. | eXist DB is an open source for XML DB",False,2025-01-20 01:04:22.283973,2025-01-20 01:04:22.283973,4bd0c214d68711ef89b40c9a3cb15cde
How is the Couch db database different or better than other document based NoSQL databases?,https://www.researchgate.net/post/How-is-the-Couch-db-database-different-or-better-than-other-document-based-NoSQL-databases?_sg=YGRdaRK8c7-Sgfb2LU2n8B1yvjqcbXn6isRdLmKZHcjIuj8mgnyqPxOWz9RsYUESfn9tbjxSeRhUsSw,2014-04-01 00:00:00,"see above,","I used CouchDB in this work https://www.researchgate.net/publication/250916398_A_Software_Architecture_to_Provide_Persistence_and_Retrieve_of_Context_Data_Based_on_Ontological_Models?ev=prf_pubMainly because the REST interface and the facility to data replication.Conference Paper A Software Architecture to Provide Persistence and Retrieve ... | If the CouchDB is better than the other NoSQL stores it would be question of the application and the feature needed for a specific scenario.CouchDB is designed for offline operation; it uses multi-master asynchronous replication. In CouchDB, multiple replicas can have their own copies of the same data, modify them, and then synchronize these changes at a later time. Comparison of different SQL implementations can be found on: http://publish.uwo.ca/~kgroling/NoSQL%20and%20NewSQL%20survey.pdf",False,2025-01-20 01:04:22.308128,2025-01-20 01:04:22.308128,4bd0c214d68711ef89b40c9a3cb15cde
Why superkey is required when we can identify a tuple uniquely through primary key?,https://www.researchgate.net/post/Why_superkey_is_required_when_we_can_identify_a_tuple_uniquely_through_primary_key?_sg=ctLIJHNh5g1rdKo7VlkHUCNt89gwgrPHEKk0BkelDOHPWa4rv8Op-kLsJiJo23CNiApdhcFii8iUnxk,2013-04-01 00:00:00,"Defination of Superkey and Primary key in wikipedia,,A superkey is a set of attributes within a table whose values can be used to uniquely identify a tuple.,,and,,The primary key has to consist of characteristics that cannot be duplicated by any other row. The primary key may consist of a single attribute or a multiple attributes in combination.,,,I've gone through many books and surfed on internet but what i found in them is,,what is primarykey and what is superkey,,but what i want to know is why superkey is required when we can identify a tuple uniquely through primarykey ?,,Thanks in advance.,",,False,2025-01-20 01:04:22.335618,2025-01-20 01:04:22.335618,4bd0c214d68711ef89b40c9a3cb15cde
"how can i start a research about  "" A topic advanced Database "" ?",https://www.researchgate.net/post/how_can_i_start_a_research_about_A_topic_advanced_Database?_sg=ou0aseZ82TwIVBcKe_3m1jPtqmG5fSptv3GpSqq8-vF4DIL_j53BS8w3Np3ebwd6lYAZaIFwaaMrJnQ,2013-03-01 00:00:00,"Computer,",,False,2025-01-20 01:04:22.362406,2025-01-20 01:04:22.362406,4bd0c214d68711ef89b40c9a3cb15cde
What are the difference between object database and object relational database?,https://www.researchgate.net/post/What_are_the_difference_between_object_database_and_object_relational_database?_sg=jpjnTk5wOF5YzQXP029x_NUKtnhWzFCNfP5gF8MlgVaxWg0rKffeQ5QaTSPA4J5MY2tMQkbQYKDiP2I,2015-01-01 00:00:00,"What are the difference between object database and object relational database?,What are Object relational database tools and  What are Object r database tools?","Object Oriented Database were proposed  as an alternative to Relational Database and are aimed at application where complex object play a major role. The approach is heavily influenced by object-oriented programming  languages and can be understood as an attempt to add DBMS functionality to a programming language environment. Object Relation Databases can be thought as an attempt to extend relational database system with the functionality necessary to support a broader class of application and provide bridge between relational and object oriented paradigms. refer the book Database Management Systems by Raghu Ramakrishnan, Johannes Gehrke, chapter object database system. | You can use this .http://stackoverflow.com/questions/24235078/object-oriented-vs-object-relational-database-difference",False,2025-01-20 01:04:22.381884,2025-01-20 01:04:22.381884,4bd0c214d68711ef89b40c9a3cb15cde
How do I convert an entity-relationship (E-R) diagram to code in opensource?,https://www.researchgate.net/post/How-do-I-convert-an-entity-relationship-E-R-diagram-to-code-in-opensource?_sg=KQhY7pOg6Od1uukB_koEKiMUXUJwAVzi7C-0xy2ueqIGY2l3UeOKNlv1YvXqyx26gyqjzMLd5LZcMF8,2014-01-01 00:00:00,"What is the best E-R diagram to query conversion tool that is available in opensource?,",,False,2025-01-20 01:04:22.404120,2025-01-20 01:04:22.404120,4bd0c214d68711ef89b40c9a3cb15cde
What is suitable Database to store the OpenStack Ceilometer?,https://www.researchgate.net/post/What-is-suitable-Database-to-store-the-OpenStack-Ceilometer?_sg=wmWWoMX2en1XA1F_A-HYS-qICa7eFhAkbzkcQ1tetKnGXc-e7m35fxJIXWbC6Ein9JMSTCuOUdsVFOM,2015-10-01 00:00:00,"Does anyone know about the which Database or Management Database System suitable to store OpenStack Ceilometer monitoring information for future processing?,Thanks to all.","Hello Salem,Can you describe the data set from the cellometer? Oracle and Sybase provide good database management systems (DBMS) but you may not want to pay for all the features of a DBMS. If you intend to use the data collected in an analysis program, you may want to write them directly to text files with appropriate delimiters, such as commas. Then your analysis program can input the text file and read the attributes directly. What kinds of queries and analyses do you plan to do with your data? These will help to determine whether it is worth the money to invest in a commercial DBMS.Best regards,Marion | Dear Marion,Thank you so much for your help. Actually I'm planning to collect cloud monitoring data using different monitoring platform (Ceilometer form OpenStack, DCIM form Intel, and Nagios) and try to make a common database for future use. So I'm confuse to use Datameer, Tableau, ...etc. Thanks againRegards, | what 's going to use this? | We are a research team planing to use this data (collected form a real data centre) to study energy usage, temperature, storage, bandwidth, optimal virtual machine placement, ... etc. in the data centre.  | redircting to; http://docs.openstack.org/developer/ceilometer/install/manual.html | Hi, we are currently following the approach to use a zabbix to collect monitoring information coming from ceilometer and other sources.  Depending on the scale of your infrastructure this could be a good approach since zabbix already allows to collect infrastructure related metrics in an easy way (via agent based approach or SNMP and many others) using its own templates and it is easily extendable to get information from ceilometer as well.Alternatively you could converge all the information from your sources into elasticsearch (directly or using logstash) and use kibana for the analysis.Cheers. | Thank you so much Andrea.",False,2025-01-20 01:04:22.433743,2025-01-20 01:04:22.433743,4bd0c214d68711ef89b40c9a3cb15cde
What are the pros and cons of using a hash index instead of a B-tree index in a database?,https://www.researchgate.net/post/What-are-the-pros-and-cons-of-using-a-hash-index-instead-of-a-B-tree-index-in-a-database?_sg=K-_NoduJvkfxIpdJA323TqMnN6OicqJ2xseAZJ03__tlIZHnFSz1xlRYEWxJInrXSe2pERgDa_IhTbI,2013-03-01 00:00:00,".,",,False,2025-01-20 01:04:22.465010,2025-01-20 01:04:22.465010,4bd0c214d68711ef89b40c9a3cb15cde
How to find the difference in time in MySQL?,https://www.researchgate.net/post/How_to_find_the_difference_in_time_in_MySQL?_sg=GGSAoe7JuDvy1Ot0CzSRu-O7uI5m8JntbU4sXwtETWwMZciUGFdFJXMay6KI3twNV9QshkAezyp_YCo,2015-01-01 00:00:00,"Order_number         T_Calc_Time,2013040100086600 09:16:34,2013040100146880 09:19:13,2013040100406920 09:35:30,2013040100893120 10:13:09,2013040100086600 10:15:14,2013040101906200 12:07:59,2013040100146880 14:48:22,2013040103401460 15:06:34,2013040103407980 15:07:16,2013040103401460 15:09:11,2013040103407980 15:24:22,select Order_number, count(Order_number),T_Calc_Time,TIME_TO_SEC(TIMEDIFF(T_Calc_Time,T_Calc_Time)) from cash_order01 group by Order_number into outfile '/tmp/ordernumber1.csv';,I have to find out that I the order number come again then i have to calculate the difference between those times.,for example the order 2013040100086600 come at 09:16:34 and leave at 10:15:14 i have find the difference and print  for each order. If the order comes only once then we have say it is gone to next day.,can any one help me?","For this, you will have to create a stored procedure in MySQL in which you will iterate through the list, select records for the currently reviewed order number and use the TIMEDIFF() MySQL function to calculate the difference in seconds between the min() and max() time-stamp. | thank you | Wouldn't it be much easier to have two columns for ""come"" and ""leave"". Then you can use the ""Order_number"" as a primary key, which appears only ones (more efficient) and you don't need to look for all the appaerances of the order number and simply calculate form the columns ""come"" and ""leave"" with TIMEDIFF() the time difference and if ""leave"" is empty, than you already know, that you can't compute the time difference. But to be honest this is quite basic stuff, which you can find in ""MySQL""-Textbooks.  | He would have to create a view or sub-query that would group the records by Order_number and select the min(T_Calc_Time) as come and max(T_Calc_Time) as leave and then calculate the difference with TIMEDIFF().This is a valid approach, but keep in mind that he has 15M+ records and creating an additional view of executing an additional sub-query would consume way too much time. | First thing the data is big and I got one day data (15GB)only, after a month I have to process a 6 months data. Second I am new to DBMS implementation. I am following DBMS by raghu ramakrishnan and MySQL cookbook by paul dubois(Completed 9 chapter still 11 chapters to go)So I simply used this query on very small data(11 records data) it produce only 8 records. and in large data it produced large number of records than original records.select a.Order_number,b.Order_number, a.T_Calc_Time,b.T_Calc_Time, timediff(greatest(a.T_Calc_Time,b.T_Calc_Time),least(a.T_Calc_Time,b.T_Calc_Time)) from ankit as a inner join ankit as b on a.Order_number=b.Order_number where a.T_Calc_Time<>b.T_Calc_Time.I am still trying to implement Mr. Milan Tair advice. Thank you very much Mr.Milan Tair for helping me. | Try this:SELECT  a.order_number,  Min(a.t_calc_time) start,  Max(a.t_calc_time) end,  Timediff(MAX(a.t_calc_time), Min(a.t_calc_time)) time_differenceFROM  ankit AS aGROUP BY  a.order_number;It should work better and faster.Try to limit the query for, say, a 100 records with LIMIT 0, 100 (at the end of the query) to see if the results are good?.",False,2025-01-20 01:04:22.485490,2025-01-20 01:04:22.485490,4bd0c214d68711ef89b40c9a3cb15cde
Is it possible to optimize the database of a particular website?,https://www.researchgate.net/post/is_it_possible_to_optimize_the_database_of_a_particular_website?_sg=f0JpM3SoH8pdJgTipc71Yb8ODiHT16yLwKXr93r4ZoofQ25M_m7JqA5rMkPPY9t2LxMK4_1HCT25xbw,2016-02-01 00:00:00,if it is possible please suggest me methods to optimize the database connections of a particular website,"It depends on the database itself. In software development particularly web application, you can't have optimised database straight away. Off course, the normal practices should be applied and the database should be optimised as it has to, but what I have learnt, some of the attributes of various tables are differently manipulated to that when it was designed. It is always a good idea to revisit most of the database as there is always a scope for improvement. Coming back to your question, more detail is required to get a precise response. | thanking u for u r response sir you are mention more details so i required that details.can u mention what they are | i can go with index for db optimization can u mention what are they  | Views, indexes and stored procedures. | Indexing.",False,2025-01-20 01:04:22.514288,2025-01-20 01:04:22.514288,4bd0c214d68711ef89b40c9a3cb15cde
How do I correct my string operations in MySQL?,https://www.researchgate.net/post/How_do_I_correct_my_string_operations_in_MySQL?_sg=aGDbRpGRunW-1l2QTBll55YPqJXYoKopf9Y2o_UtrTN--mI88xRW9pdp5AZS8RYdZdKU5Mv4HXc3k7E,2015-02-01 00:00:00,"I have column where the values in that column will have some name in capital alphabet the length is 10 char but if the name is small,The values in this field will be padded with leading spaces (char 'b') when < 10 chars.,E.g. name  ABC will be,""bbbbbbbABC"",When I print, I should print only ABC.","https://dev.mysql.com/doc/refman/8.0/en/string-functions.html#function_replace | REPLACE should do the trick: http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_replaceIf you got a table 'MyTable' with a column 'MyName' then the SQL statement would be:SELECT REPLACE(MyName,'b','') FROM MyTable | Thank you Mr.Rene Berndt. | There are many ways to do this but the best is SELECT REPLACE(MyName,'b','') FROM MyTable, suggested by René Berndt | what are other ways? Sanjay | thanks for taking interest in my response. Off-course i can give you other way but need little bit of clarification. What are the cases where above given method (way) fails. | hi you can use LTRIM () function may it will help you | https://dev.mysql.com/doc/refman/8.0/en/string-functions.html#function_replace",False,2025-01-20 01:04:22.552309,2025-01-20 01:04:22.552309,4bd0c214d68711ef89b40c9a3cb15cde
Anybody know good GUI for creating Biological Relational Database?,https://www.researchgate.net/post/Anybody_know_good_GUI_for_creating_Biological_Relational_Database?_sg=DhDLRZGCQJQBCOvPlLDjXwc-5NQG_M4s808tEeoc0iHRwpRPWLlpUkE0foC7hE1fOjUwlLM53wKtxcI,2013-07-01 00:00:00,"I want to make an Integrative database which contain Many table which are integrated to each other I want some Software or GUI or Platform which can easily create, integrate and make user interface from data base.?,","Try to use GuiGenie or Data Wizard for MySQL | Microsoft Access ver 2013 is a very good choice.There are plenty of online and offline guides and tutorials and books that you can rely on them when had questions. | My favorite is Claris FileMaker, which has a very easy interface, plenty of books and a very helpful community. | My favorite is OpenBioMaps :D which was designed to create an manage biodiversity related databases...",False,2025-01-20 01:04:22.573492,2025-01-20 01:04:22.573492,4bd0c214d68711ef89b40c9a3cb15cde
Can you give me suggestions regarding this database?,https://www.researchgate.net/post/Can_you_give_me_suggestions_regarding_this_database?_sg=9SawYjSXfLEdhJsJE7525PMUNhRb3ahJYkPgFaluU5H5lAsDd91j3sx7XqfWrOyl8Gl92aLmyMjIceE,2014-07-01 00:00:00,"I have been working on the development of a database regarding RNA classification. Now it is almost done. I have attached the link of the database. I have tested it on Mozilla and Chrome. Any suggestion regarding making it better would be much appreciated. Thank you all.,http://www.saha.ac.in/biop/www/HDRNASv2.0.html#home","Hi Debasish, great work.I also working in something similar using mysql, my goal is a protein folding prediction, but Im still in the very beginning and I'm still learning about biochemistry but maybe we can share some info about mysql.My skype is thiagobenazzimaiahttps://docs.google.com/document/d/1kmqhi17KvmeS7W4jQlMi68Ng4YmXRaAD4Q51DW06qjU  | That is very nice. I would be happy, if I can be of any help. | Hi Debasish, do you have skype? | Sorry , I didn't say you reply. I do have skype. The id is debasishbib",False,2025-01-20 01:04:22.592334,2025-01-20 01:04:22.592334,4bd0c214d68711ef89b40c9a3cb15cde
"How to show process of horizontal, vertical fragmentation, derived horizontal fragmentation including clustering process in vertical fragmentation?",https://www.researchgate.net/post/How_to_show_process_of_horizontal_vertical_fragmentation_derived_horizontal_fragmentation_including_clustering_process_in_vertical_fragmentation1?_sg=HJ-PY_EdeJw2tg0xOY5uVXI6vSVZd1dcZrTP5seGVosSixckLVM1_MGLaDtx32LYL4TNUpfOX7MSZ_Q,2012-11-01 00:00:00,"It's the problem I have to solve, I don't have much knowledge about Distributed database, can any one help me?,",,False,2025-01-20 01:04:22.615465,2025-01-20 01:04:22.615465,4bd0c214d68711ef89b40c9a3cb15cde
What are the problems and theses proposed in the field of: Big Data database systems?,https://www.researchgate.net/post/What-are-the-problems-and-theses-proposed-in-the-field-of-Big-Data-database-systems?_sg=Hk0Y-SRaQcY_KyoLoNJb2ce8QBd-dJI9So_RccbX4VoeS89Ld5949VIXWCjzLuD3XDhDQ2zHwRTxRIE,2019-03-01 00:00:00,"What kind of scientific research dominate in the field ofBig Datadatabase systems?,,Please, provide your suggestions for a question, problem or research thesis in the issues:Big Datadatabase systems.,,Please reply. I invite you to the discussion,,Best wishes","Informative question | Dear Friends and Colleagues of RGBelow are some issues related to Big Data database technologies that can be developed scientifically: - application of data processing technology in Big Data database systems for modern education 4.0,-  improvement of forecasting of natural, climatic, economic, economic,  financial, social etc. phenomena based on analyzing large data sets,-  analysis of sentiment, opinions of citizens, Internet users regarding  brand recognition of companies, customer reviews of specific services  and products, views on various topics, citizens' worldview based on the  analysis of large collections of information downloaded from various  websites, from comments downloaded from social media portals,-  analysis of information and marketing services of commercially  operating companies that carry out specific analyzes of sentiment,  citizens' opinions, Internet users regarding brand recognition, customer  reviews of specific services and products etc. on behalf of other  companies that purchase specific analytical reports,-  analysis of the possibilities of cooperation, synergy, correlation,  conducting interdisciplinary research, connecting Big Data database  systems with other information technologies typical for the development  of the current fourth technological revolution called Industry 4.0,  which include technologies such as: cloud computing, machine learning,  Internet of Things, Artificial Intelligence, etc.Best wishes | I suggest the following questions and research problems in the above topic:
Are  commercial banks already introducing sentiment analysis conducted on  Big Data data collected from social media portals to the standard of  customer verification procedures?
Inclusion  of the sentiment analysis conducted on Big Data collected from social  media portals could be an important additional information on the  economic and financial situation of the potential client. This type of  information can be a significant additional factor of full verification,  eg creditworthiness of a potential borrower. I know that some service  companies, marketing companies, insurance companies and banks include  the sentiment analysis carried out on data collected in Big Data  database systems collected from social media portals for verification of  potential customers. But is it already becoming a standard or is it  only at the design stage for now? | In addition, I suggest the following questions and research problems in the above topic:
Will Big Data database technologies be available in the future also for companies from the SME sector?
Advanced  technologies of digitalization and automation of data processing first  find their application in business. Then also in public institutions can  be introduced including in the field of e-governance. This also applies  to Big Data database technologies, which is applicable in various  sectors of the economy, but due to the high investment costs of  implementing this technology in the business processes of business  entities, so far only large corporations and larger enterprises can  afford such technologies. However, in the future, investment costs of  implementing tech technologies into business processes should decrease  and processing technologies and data collection in Big Data database  systems should be available also for smaller companies, including  business entities of the SME sector.  | Another proposal for a research topic in this field:
Will  the information collected and processed in the Big Data database  systems in future be able to accurately check future climate disasters?
In  my opinion, information obtained from various research centers,  meteorological centers, satellites, etc., then collected and processed  in Big Data database systems should help in more and more precise  prediction of new, unfavorable weather phenomena, including climatic  cataclysms and others. In this way, earlier and in a more planned way,  crisis management systems can be organized in the situation when the  predetermined flood disaster becomes real and will happen. Gradually  increasing computing power of powerful computer servers managing  platforms of Big Data database systems, implemented artificial  intelligence, increasing number of verified historical data on the  overall climate phenomena on Earth will allow in the future more  precisely, more accurately determine the level of threats, risk value,  predict time, place and scale adverse weather events, i.e. also  cataclysms that threaten people's lives. | I propose the following proposal for a research topic in this area:
Will  future Big Data database systems supported by artificial intelligence  be used in precise forecasting in order to verify futurological  projections?
Currently,  it is difficult to define this type of analytic problem. The key issue  is forecasting future global problems. It is necessary to collect  additional analytical data over the next years, and perhaps in the 21st  century, in huge Big Data database systems supported by another  generation of artificial intelligence, it will be possible to predict  what may happen to the planet Earth in the future. | In addition, I suggest the following questions and research problems in the above topic:
Do Big Data companies use Business Intelligence analyzes in enterprises operating in your countries?
The Big Data database technology is finding new applications in business.
Multi-criteria  processing of huge data sets collected in Big Data database systems  allows preparing reports in a relatively short time according to given  criteria.
The report development time depends mainly on the computing power of Big Data servers.
In  processes of complex economic and financial analyzes, risk management,  etc. for the purpose of determining the economic and financial situation  of business entities, they are increasingly carried out in computerized  analytical platforms of the Business Intelligence type.
Perhaps in the future, artificial intelligence will also be involved in this field of analytics.
In  some countries, IT companies have been operating for several years,  which develop Big Data database technology for commercial and business  purposes.
Some technology companies produce Business Intelligence platforms for business entities.
Research centers of the largest technology companies on the Internet develop technologies of artificial intelligence.
It is only a matter of time to combine these various analytical and database technologies in computing cloud computing. | Another proposal for a research topic in this field:
What  will be the directions of development of analytical processes of  sentiment analyzes on data collected in Big Data database systems in the  future?
In  order to analyze the sentiment on downloaded data from social media  portals (such as Facebook, Tweeter, LinkedIn, but also YouTube,  Instagram ...) and aggregated in Big Data database systems, it is  necessary to use specialized software for extraction and analysis of  these data.
The  quality of the data transferred to, for example, excel sheets depends  on the quality of the extraction process carried out with the help of  specialized software.
Then,  the quality of data analysis software in Excel sheets or in systems of  computerized analytical platforms depends on the result obtained, the  answer to the question given to the collected, initially unstructured  data in the Big Data database system.
In  the future, artificial intelligence may be used for this purpose, and  the whole process of purposeful analysis of collected data will proceed  in a much more effective, automated manner, less probable errors, will  be a cheaper research process and will be carried out much faster even  on much larger information collection than current. |  I propose the following proposal for a research topic in this area:
Will  artificial intelligence combined with the analysis of data collected in  Big Data database systems be used in automated forecasting of  valuations of securities and other assets on capital markets?
In  the background of the plot of the film ""Transcendence"" from 2014,  directed by Wally Pfister, the topic of analysis is analyzed by a  computerized system combining artificial intelligence with human  consciousness loaded into a computerized system of artificial  intelligence connected to Internet resources and using the resources on  its own.
This  independence also means access to various databases, including internal  Big Data database databases belonging to certain corporations,  including listed companies that are issuers of securities.
The  artificial intelligence connected to the Internet, according to a  specific strategy, also independently conducts transactions on the  market of valuable securities.
In  addition, it establishes statrtsets offering innovative technologies,  which in a short time become large capital companies characterized by a  high capitalization of exchange quotations of shares of these companies  listed on stock exchanges.
The  above-presented film ""Transcendence"" presented above picture of  integration of artificial intelligence, human consciousness and Internet  resources is a picture of typical science fiction.
However,  on the other hand, the function of this image is also to inspire to  discuss the potential possibilities of integration of the  above-mentioned elements into one system of autonomous and working in  the Internet resources artificial intelligence, in addition also  containing some human feelings.
The above image from the movie ""Transcendence"" became an inspiration to formulate the following question below.
The  mentioned motif from the movie ""Transcendence"" looks impressive and  convincing in this film mainly because it has a full spectrum of  innovation.
The  use of new, innovative instruments for forecasting specific economic  categories usually works until these innovative instruments continue to  be innovative, ie until they are disseminated to the majority of  participants in specific markets. | In addition, I suggest the following questions and research problems in the above topic:
Are  there any ongoing work to implement artificial intelligence for the  analysis processes of large collections of information collected in Big  Data database systems?
Business  entity management processes are more and more often supported by  computerized Business Intelligence platforms that facilitate  multi-criteria analysis and reporting.
Probably in the future, the business analyst will be supported by artificial intelligence.
It  would be a great advance in the field of automation and objectification  of multi-criteria economic analyzes of business entities.
Complex,  multi-criteria analyzes regarding the verification of large companies'  operations require aggregation and analytical processing of large data  sets in Big Data database systems.
However, in what direction will technological progress be realized in this field?
In  the future, as part of the progressing computerization of analytical  processes, it will be possible to implement artificial intelligence to  the processes of analyzing large collections of information collected in  Big Data database systems.",True,2025-01-20 01:04:22.632828,2025-01-20 01:04:22.632828,4bd0c214d68711ef89b40c9a3cb15cde
In which fields do the technologies of information processing and analysis in Big Data database systems apply?,https://www.researchgate.net/post/In_which_fields_do_the_technologies_of_information_processing_and_analysis_in_Big_Data_database_systems_apply?_sg=Yywh4kmvCeq5v2COypvwFaKT-Itb2qt_NR1UMqoF5l183PGIAIMVMvbnnh9bi_qh0Fgy-UwMW1At1KE,2019-01-01 00:00:00,"Below are some issues related to Big Data database technologies that can be developed scientifically:,,- Application of data processing technology in Big Data database systems for modern education 4.0,,,- Improvement of forecasting of natural, climatic, economic, economic, financial, social etc. phenomena based on analyzing large data sets,,,- Analysis of sentiment, opinions of citizens, Internet users regarding brand recognition of companies, customer reviews of specific services and products, views on various topics, citizens' worldview based on the analysis of large collections of information downloaded from various websites, from comments downloaded from social media portals,,,- Analysis of information and marketing services of commercially operating companies that carry out specific analyzes of sentiment, citizens' opinions, Internet users regarding brand recognition, customer reviews of specific services and products etc. on behalf of other companies that purchase specific analytical reports,,,- Analysis of the possibilities of cooperation, synergy, correlation, conducting interdisciplinary research, connecting Big Data database systems with other information technologies typical for the development of the current fourth technological revolution called Industry 4.0, which include technologies such as: cloud computing, machine learning, Internet of Things, Artificial Intelligence, etc.,,In what other areas are the technologies of processing and analysis of information in Big Data database systems used?,,Please answer,,Best wishes","Hi,It seems that technologies of information processing and Big Data apply to information and knowledge management, and to business and knowledge systems. | Good morning. I am currently working on a doctoral research that, once completed, will enable the understanding of some variables that may influence the learning factors of the high school students. One of the difficulties I face is how to feed important variables into a particular data mining cross. Example: socioeconomic variables. It is known that the social condition of students influences learning and educational development. | The above discussion inspired me to the following considerations:In my opinion, the scope of synergy and possibilities of combining applications of various advanced information processing technologies, including data analysis eg on Business Intelligence platforms based on large data sets collected in Big Data database systems for the purpose of improving information security management processes, including information transferred, increases. on the Internet, collected in Big Data database systems and used to carry out various economic, financial and other analyzes.  | Dear Colleagues and Friends from RGThe key aspects and determinants of applications of data processing technologies in Big Data database systems are described in the following publications:Article APPLICATION OF DATA BASE SYSTEMS BIG DATA AND BUSINESS INTEL... Article The Big Data technologies as an important factor of electron... Article The Technological Solutions Big Data and the Importance of B... I invite you to discussion and cooperation. Best wishes | Dear Colleagues and Friends from RG,To the above discussion I would like to add the following conclusion formulated as a summary of my previous considerations on this topic: The growing importance and applicability of Big Data Analytics technology for forecasting complex natural processes and climate change.Otherwise the above discussion inspired me to formulate the following question:Should the improvement of the water management planning process in a situation of progressive climate change, including drought occurring more and more often, use predictive methods using computerized analytical platforms equipped with Business Intelligence research tools, Big Data Analytics, artificial intelligence and other advanced data processing technologies Industry 4.0?On the basis of the above considerations and conclusions from the discussion on interesting issues discussed, I formulated the following thesis that as part of improving the water management planning process in the situation of progressive climate changes, including drought occurring more and more often, prognostic methods should be used using computerized analytical platforms equipped with Business Intelligence research tools, Big Data Analytics, artificial intelligence and other advanced data processing technologies Industry 4.0.Below I have described the key determinants confirming the formulated research thesis. To the above discussion I would like to add the following conclusion formulated as a summary of my previous considerations on this topic: The use of ICT and Industry 4.0, including artificial intelligence, Business Intelligence research tools, Big Data Analytics and other technologies of computerized, multi-criteria, advanced data processing.Clean water is primarily necessary for human life and for the functioning of biological ecosystems.Clean water is essential for agricultural production and many industries. Because the resources of clean water are shrinking in many places around the world, it will be necessary to improve the technology of purifying polluted water in rivers, lakes, etc.The issue of water purification is therefore one of the most important factors of sustainable pro-ecological development based on the concept of a new, green economy.Climate change, i.e. the ongoing global warming process, drains many areas of the tropical and subtropics, and fresh water resources are therefore falling. This will probably be one of the most serious consequences and problems of the global warming process, which is moving faster and faster. The issue of falling fresh water resources is one of the most serious problems and challenges for humanity in the 21st century. It is also a problem for biological ecosystems that undergo drying, and therefore biodiversity, including flora and fauna biodiversity on Earth is also decreasing. Climate change, mainly in terms of the global warming of the Earth's climate will cause in many places stepping of existing forest areas. There will be droughts in areas where these negative weather anomalies have not occurred. these processes will reduce the amount of water both on the Earth's surface and in the subcutaneous layers of the soil. Also, underground watercourses located in shallower underground layers may dry out over a period of several years in the area covered by long-lasting drought. This type of negative process of warming and dehumidifying the climate in a given area may lead to desertification of areas where vegetation previously occurred. In addition, these considerations should also take into account the impact of agriculture on the condition of rivers, including the quality and purity of water in rivers is large. Fertilizers dripping into rivers change the biological ecosystem in rivers. Mountain rivers in some countries are the only ones that are not yet seriously polluted. Another issue is obtaining drinking water from desalinated sea water. Due to the fact that there is less and less clean water on Earth. In connection with the development of industry, increasing water consumption in households, deep water exploitation, increasing pollution of rivers, ponds, lakes and seas as well as the progressing global warming process, clean water resources are falling.In connection with the progress of civilization, the development of an industry that consumes large amounts of water, and also in connection with the progressive warming of the Earth's climate, the accelerating process of global warming, increasingly frequent cataclysms and climatic anomalies, such as the increasing frequency of droughts, the resources of available, clean water are decreasing. As part of protecting natural resources, techniques for efficient and economical water resource management should be improved. The industry should be developing technology for purifying and reusing water. In addition, water purification and reuse techniques in households and agriculture should be improved. As part of the purification of the environment, sewage treatment plants should be built in each city so as to reduce the discharge of sewage containing toxins harmful to living organisms, to reduce the flow of sewage into rivers, lakes, seas and oceans, which are increasingly polluted.Due to the growing need to implement the principles of sustainable pro-ecological development in recent years, ecological innovations arise mainly in the field of renewable energy sources, improvement of waste segregation techniques, recycling, treatment of polluted water, reclamation of a devastated natural environment, energy-saving construction, electromobility of the automotive industry, etc. more ecological innovations, new technological solutions and technical improvements that are part of sustainable ecological development are also emerging in many other fields of science.Droughts that are becoming more frequent in many green and agricultural areas are also associated with decreasing rainfall. Rain is necessary in many climatic zones for biological life to exist, for biodiverse natural ecosystems. In addition, rain in many climate zones and countries is essential for agricultural development. Rain is also a source of water in many geographical places, which then penetrates deep into the Earth, feeds water, subcutaneous watercourses, underground, deep water streams. In addition, rain supplies water to rivers and lakes, the living environment of many species of aquatic plants and animals, etc. Rain is necessary for the efficient functioning of ecosystems, but also for people. In some places on Earth there is less and less rain. This is a threat to the natural environment, to biological ecosystems, and long-lasting droughts appear. It is associated with global climate change, probably with global warming, global warming, and rising global annual temperatures.Sustainable development can be achieved by various methods. Which methods will be chosen is determined by many factors of the environment, the environment of specific economic processes as well as the specifics of economic undertakings and the national economy. However, in the absence of a key development factor, a key raw material, such as water, may be a significant cost barrier to the implementation of the process of achieving sustainable development. Sustainable development in a situation of constant irrigation of agriculture is not excluded, but will generate high costs. In such a situation, profitable projects should be developed in the national economy that will finance the costs of the said irrigation. It cannot be ruled out that irrigated poor quality soil will produce high yields with appropriate fertilization and use, high crop production will be generated and after a period of several or more years it will be possible to create more complex flora ecosystems, including forest next to arable fields and in this the process of achieving sustainable development can be successively improved. Then sustainable development will be analyzed, implemented and improved in terms of the national economy.In connection with the progress of civilization, the development of an industry that consumes large amounts of water, and also in connection with the progressive warming of the Earth's climate, the accelerating process of global warming, increasingly frequent cataclysms and climatic anomalies, such as the increasing frequency of droughts, the resources of available, clean water are decreasing. As part of protecting natural resources, techniques for efficient and economical water resource management should be improved. The industry should be developing technology for purifying and reusing water. In addition, water purification and reuse techniques in households and agriculture should be improved. As part of the purification of the environment, sewage treatment plants should be built in each city so as to reduce the discharge of sewage containing toxins harmful to living organisms, to reduce the flow of sewage into rivers, lakes, seas and oceans, which are increasingly polluted.Sustainable ecological development is a necessity, it is a challenge for humanity to quickly implement it in order to slow down the global warming process. Sustainable pro-ecological development is a necessity for humanity to avoid extermination being a derivative of the increasingly faster global warming process and the forecasted increase in the scale of climate cataclysms that may appear at the end of the 21st century if on the global scale in the next several decades ecological innovations, widespread renewable sources of energy, electromobility will not be developed, the efficiency of waste segregation, recycling, management of clean water resources, etc., however, objective measurement of ongoing processes towards implementation of sustainable ecological development is difficult. In my opinion, the methodology for measuring sustainable sustainable economic development should be built on a set of key expected effects of implementing this type of development. In addition to the effects of sustainable sustainable economic development, the methodology of scoring analysis should also take into account all the important determinants of ecological reforms, including, first of all, the issues of implementing ecological innovations, the scale of development of renewable energy sources, electromobility, increasing the efficiency of waste segregation, recycling and also improving management of clean water resources management, etc.The analysis of predictions and the continuation of specific processes could relate to e.g. climate, market, space, geological, natural, economic processes, etc.Should the basic components of this type of system be the following components of computerized technologies for advanced information processing typical of the current technological revolution known as Industry 4.0.?:- Big Data database system,- Business Intelligence analytical platform,- data processing in the cloud computing,- artificial intelligence.In addition, if this system should have convenient access from the Internet, this type of solutions can be enabled through the Internet of Things technology. In this way, access to the system or some of its modules could be implemented e.g. from smartphones, tablets, laptops and other mobile devices.Therefore, if you have advanced research instruments that help you carry out prognostic analyzes. For example, tools that allow you to perform sentiment analyzes on large sets of information downloaded from the Internet and stored in Big Data database systems. If this type of analytics is combined with advanced information processing instruments on Business Intelligence analytical platforms, then it is possible to build accurate research tools enabling precise analysis of predictions of anticipated processes for subsequent periods in the future.Can this type of research help analyze key processes in environmental issues, natural ecosystems and biodiversity? Can this type of research be helpful in precisely defining complex, multi-faceted progressive processes regarding:- changes in environmental pollution diagnosed in specific areas of the globe?- precise diagnosis and analysis of the effects of progressing processes undertaken in the field of environmental protection, natural ecosystems and biodiversity?- observation, data collection, examination and analysis of the progressive process of greenhouse gas emissions?- observing, collecting data, examining and analyzing the progressing global warming process and examining the effects of this process diagnosed in specific areas of the globe?- collecting data that could help in forecasting more and more frequent weather anomalies and climatic disasters?- collecting data that could help in forecasting further natural disasters, e.g. developing viral, fungal, bacterial diseases and caused by insects and other pests in arable fields?- analysis of the change in the state of clean, potable surface, subcutaneous and deep water in green, agricultural and also those that are draining and sterilizing?In my opinion, currently developed techniques of satellite information gathering for the needs of analyzes carried out on large data sets carried out in Big Data database systems can be helpful in the research topics presented above. What other research topics can be implemented in support of satellite information collection for the needs of analyzes carried out on large data sets made in Big Data database systems?In view of the above: Do you agree with my opinion that in the context of the projected acceleration of the global warming process, humanity should, in order to avoid a global climate disaster, should prioritize in the 21st century the change of the classic economy to a new green economy to develop economies according to the concept of sustainable pro-ecological development, in replace classic energy sources based on burning minerals with renewable energy sources. In addition, greenhouse gas reduction programs and improvement of management and management of clean water resources should be launched in economic processes as soon as possible and as much as possible. Therefore, it is also necessary to develop ecological, material and energy innovations, including the improvement of renewable energy technologies so that pro-ecological energy solutions are becoming cheaper to implement and develop, and become more common. The key issue is also to improve the management and management of clean water resources and also to develop ecological innovations for obtaining clean, potable water from deep deposits located underground, e.g. under the Sahara Desert in Africa, obtaining water from the atmosphere using liquefaction processes and by improving seawater desalination technology.In line with the above, in my opinion, as part of improving the water management planning process in the event of progressive climate change, including drought occurring more and more frequently, forecasting methods should be used with the use of computerized analytical platforms equipped with Business Intelligence, Big Data Analytics, artificial intelligence and other research tools advanced data processing technologies Industry 4.0.Do you agree with me on the above matter?I conduct research in this area. The conclusions of the research I published in scientific publications that are available on the Research Gate portal.In view of the above, I am asking you the following questions:- What is the impact of the global warming process on freshwater resources and biodiversity on Earth?- Improving the technology of purifying polluted water as an element of sustainable pro-ecological development based on the concept of a new, green economy?- Is it possible to objectively achieve sustainable development in the absence of a significant production factor in the national economy?- What is the impact of agriculture on the purity of water in rivers?- What technologies for water purification and desalination should be developed?- Is there a need for water purification in the environment, in industry and for household needs?- What elements of information technology should consist of an analytical and database system used to forecast the continuation of trends for multi-faceted processes?- Does technological progress contribute to the improvement of techniques for conducting analyzes of forecasting future processes?- Are you familiar with the techniques, goals and functions of satellite information collection for the purposes of analyzes carried out on large data sets of information collected in this way and stored in Big Data database systems?- Should improvement of the water management planning process in the event of progressive climate change, including drought occurring more often, use prognostic methods using computerized analytical platforms equipped with Business Intelligence research tools, Big Data Analytics, artificial intelligence and other advanced processing technologies Industry 4.0 data?- Do you have multifactorial models that use the results of advanced analysis of large data sets in Big Data database systems that could help diagnose the main determinants and predict the pace and negative effects of the progressing global warming process, climate change, future forest fires and drainage of agricultural land and green?- How to build a model methodology for measuring sustainable sustainable economic development?- Are there banks and / or enterprises that take into account forecast climate change in their business decisions?- How should the application of Industry 4.0 technology be developed to forecast complex natural processes and climate change?- Is the importance and application of Big Data Analytics technology for forecasting complex natural processes and climate change growing?What do you think about this topic?What is your opinion on this topic?Please replyI invite you to discussionthank you very muchBest wishesDariusz Prokopowicz | Dear Avishag Gordon, Ivonaldo Silva, Nissrine Souissi, Srdjan Atanasijevic,    
Thank you very much for your inspiring, interesting and highly substantive answer.
I am very glad that an interesting discussion has started. Your statements confirm that the above-mentioned issues are current and developing. Yes, Big Data Analytics technology finds more and more applications in the analysis of complex, multi-criteria processes of researching large data sets. 
Thank you very much and best regards,

Have a nice day,
Dariusz Prokopowicz  | During the SARS-CoV-2 (Covid-19) coronavirus pandemic, one of the important elements of pandemic risk management and the improvement of anti-pandemic safety and crisis management systems is forecasting and modeling the future development of subsequent pandemic waves, taking into account various environmental factors. In connection with the processing of large sets of information, specific information technologies ICT and Industry 4.0 may be used in the process of forecasting and modeling the future development of subsequent pandemic waves, including analytics carried out on Big Data Analytics platforms.  Regards, Dariusz Prokopowicz  | Hi,In an answer to the original question, this subject belongs to the following fields: AUTOMATION CONTROL SYSTEMS ‎
BIOTECHNOLOGY APPLIED MICROBIOLOGY 
ENGINEERING
FOOD SCIENCE TECHNOLOGY  | Dear Avishag Gordon,  Thank you for providing the areas and fields of application of analytics implemented on Big Data Analytics platforms. Your answer confirms the thesis about the growing number of areas and areas of application of this analytical technology included in the Industry 4.0 technology.  Regards, Dariusz Prokopowicz  | Dear Rogério Luís De Carvalho Costa,  Yes you are right. You have indicated many key areas of analytics applications conducted on Big Data Analytics database platforms. thank you for the link to the article on this topic. I also conduct research on this issue. I have published the results of my research in the field of Big Data Analytics applications in the publications available on my Research Gate profile.  Best wishes,  Dariusz Prokopowicz ",True,2025-01-20 01:04:22.672175,2025-01-20 01:04:22.672175,4bd0c214d68711ef89b40c9a3cb15cde
What is the most popular database model to be used in business?,https://www.researchgate.net/post/What-is-the-most-popular-database-model-to-be-used-in-business?_sg=dlhjrIuEmW5gUuxdpMDx2xEDjp7vIQHiV-wtUetiaD9D9dEoBdHr2rcradvwB4z5XAG5vJiOwonXxXM,2015-01-01 00:00:00,What is the most popular database model to be used in business? I would be grateful if I could have an evidences for the answer.,"There's little question that the relational database model is the most popular and will be for some time. Relational databases include Oracle's database, Microsoft's SQL server, MySQL and Postgres. | Dear Lan, Do you have any evidence e shows that, relational database model is the most popular and will be for some time. | Simply look at the database market. It largely consists of Oracle, Microsoft, IBM and Postgres. These companies sell relational databases. It is my opinion that relational will be the dominant model for some time.  | Depends on size of your business, requirements and associated front end tools. | I agree with Ian. Some additional evidence (probably a consequence of the market dominance by the big players) is that most NoSQL systems after a while start offering SQL related interfaces like JDBC | I also agree with Ian, relational model DB is the most popular in business, followed by dimensional model (with most of the time is implemented over relational model). | Well, I am sure you already hear about everything depends in your requirements or in your design. The market right now have some preferences for relational models, first of all, the relational database is simple to understand and is easy to learn. But is not the only way, some people prefers OLAP models, very fast but kind of complex to understand.I think is easier if you explain us your requirements and then we can see which model is best for you. | Historically (the last 30 years) the relational database model under a third normal design has been used by almost all businesses and is reflected in the major software offerings from Oracle, Sql Server and so on.The issue is that the relational model has issues scaling to Big Data types of data, here non-SQL databases such as Hadoop are being used to deal with very large data. So, if you have a small amount of complex data then the relational model still works best, if you have large amounts of mostly unstructured data then the newer No SQL databases probably represent the future.Scott.  | Relational Database Model  | In South Africa many companies especially in the financial services and related sectors use rational databases ... mostly Oracle for transactional data with some now using SQL Server due to robustness and ability to scale. M(OLAP) largely used for analysis to get insights on clients, value chain effectiveness, trends, predictions etc.Most corporates use propriety software and avoid open source platforms ... these decisions are based on many factors, namely license agreements, considerations on cost of technology and / or ownership; economies of scale, skills availability and / or shortage plus cost thereof, security, interoperability, scalability, backward and forward compatibility etcetera.However, most academic institutions and scientific facilities use open source platforms more and adopt open technologies like Open OS (Linux, Ubuntu etc.), build EDRMSs using Fedora, adopt Hadoop for Big Data etc. ... have and build skills required to support these environments within.Hope thsi helps ... :-)",True,2025-01-20 01:04:22.721461,2025-01-20 01:04:22.721461,4bd0c214d68711ef89b40c9a3cb15cde
What is the main problem that prevents a quicker adoption of NoSQL databases?,https://www.researchgate.net/post/What-is-the-main-problem-that-prevents-a-quicker-adoption-of-NoSQL-databases?_sg=0EGga1G-sEyQxTrD1_aktK1pIsNvnF2FP6GZR8s9zj5AQarFK_YQ3b33EqJd--o1G855FY0RpyQL5u4,2015-01-01 00:00:00,"Are these problems the ones that are usually involved with new systems, where new skills are needed?","no, in my opinion, each database technology is addressed to manage certain data (structured, semi-structured, non-structured) and fulfil certain criteria, depending on your necesities you will choose one or another. Furthermore, relational engines are including new ways to store and query data streams faster, so in many cases NoSQL solutions aren't needed. | NoSQL is not meant to replace traditional RDBMS. To answer your question, for me the main problem preventing their adoption is the fact that they are ""schema less"", you have to build yours depending on the application need and that they use different consistency approaches: eventual consistency etc.. but not ACID which could be another obstacle for certain type of apps. In the words, if your app doesn't have VERY high scalability requirements RDBMS are still preferable. | I am not quite sure what you mean with slow adoption or problems. NoSQL databases serve a specific purpose: to store unstructured or semi-structured data. Many (I would say the vast majority) of problems deal with structured data (or data that can easily be structured) and thus there is no need for a NoSQL approach. However, in those areas where NoSQL can be useful, it is largely adopted. Hadoop is a very successful technology, as is MongoDB (and there are plenty of others). Related technologies, such as JSON, are also rapidly gaining popularity in a large number of applications.That said, MapReduce is a completely different way of thinking about a problem, and it takes training and effort to solve a problem in a MapReduce manner as opposed to the approaches used in more traditional solutions, so the requirement of new skills can indeed be a hurdle. | look at our recent experimentation in a conversion of SQL to NoSQL and see the results. We suggest that some guidelines would be helpful because the current developers have years of SQL thinkinghttp://publicationslist.org/data/a.april/ref-474/2165-7866-4-137.pdf | Alain - nice. Thanks for sharing :)Miroslav - NoSQL != NewSQL, it's actually been around longer than SQL/RDBMS. It's just been jazzed up a bit. The real problem is that linear programmers are always looking for trivial answers to the database paradigm. Ironically, the simplest solutions are the best, and the most difficult to wrap one's head around at first. For example, take 'implicit negation'. Fascinatingly simple, but only doable in a DBMS, more so in an RDBMS. However, trying to teach both the methodology, and relate quantitative and qualitative benefits is at times near impossible because it requires changing how one thinks about data. I used an example for my dissertation in which over the course of lunch I produced an ANSII Standard SQL solution for a PhilFactor SQL competition that considerable outperformed the winning solution (attached). It was simply a matter of reducing the problem to it's atomic simplicity. However, simple does not always equal 'trivial'. :) | I watch a MongoDB video whit the theme of: Hybrid databases MongoDB+MySQL.They accept that where MONEY is involved, that part has to be RDBS, because the robusteness of concurent threads of RDBS. Where it is not important, if one LIKE does not appear in the next milisecond, there the NoSQL is good enougth. | I do understand that RDBMS has got a place. But if RDBMS has an additional features what NoSQL have then it will incredible improve storage of multimedia data like pictures, video or document. Then it will be possible to avoid a BLOB or more be able to define new commands apart of select, from etc.NewSQL is good move but still is not solving problem complete.I mean there should be already some ORM or OLAP or anything else what will make for programmers no interest at all what is behind. I thought there could be even some level of combination. Of course I know there is a CAP theorem.There are MS LINQ or Hadoop but NoSQL is still just solution for storing/retrieving huge data .Is that really only technical problem or political too? | Miroslav,>>I mean there should be already some ORM or OLAP or anything else what will make for programmers no interest at all what is behind. Again, one should not trivialize the realities of 'data'. As an analogy, by trade I was a master finish carpenter having grown up with a number of carpenters in my family before I  moved on to tech around age 25...and was forced to learn all that preceded finish carpentry  from staking, pouring the foundation, and framing in order to make me a more effective finish carpenter (got to know where the backing is and why). In the same way, programmers should have to learn aspects of operating systems and data architecture, otherwise they might as well just use keyed files or a surrogate keyed database table. Performance will always be a challenge though for any problem domain of sufficient complexity. This applies to DBMS, RDBMS, ODBMS and all their flavors of language whether it be SQL, NoSQL, C#, etc. >>Is that really only technical problem or political too?It's actually an unawareness or obliviousness issue...that, and folks always want to have their cake and eat it too <lol>",False,2025-01-20 01:04:22.747366,2025-01-20 01:04:22.747366,4bd0c214d68711ef89b40c9a3cb15cde
How can we use the potential resources in Genome since it is such a large database?,https://www.researchgate.net/post/How_can_we_use_the_potential_resources_in_Genome_since_it_is_such_a_large_database?_sg=uUUf1mNmKiAKxVQxL3X1E8OM2xOGlo_ffxda3NNfOUxPiyBVnQl6emrkxpJqwi_FHDhndoekzSwg8bA,2014-04-01 00:00:00,"Genome is a big database, how can we use the potential resources? Are there good methods or ways in addition to first mapping? I think the study of methods and tools about utilization of the sequenced genome is more important, such as studying statistics.,",,False,2025-01-20 01:04:22.777803,2025-01-20 01:04:22.777803,4bd0c214d68711ef89b40c9a3cb15cde
Are there ways to develop databases for prisoner re-entry programs?,https://www.researchgate.net/post/Are-there-ways-to-develop-databases-for-prisoner-re-entry-programs?_sg=mc_0h2uK3oaYeMqZlR2XEHezgU6zyl7PdrOCLRznr3Lx0pGQ1hkAELzS9F_Uz-SXdWX7XEOb2sUm-YQ,2016-02-01 00:00:00,Does anyone know of person who might be able to assist in developing a database of prisoner re-entry resources that can be developed initially for Pennsylvania and then potentially expanded nationwide? We are interested in a potential volunteer to develop such a program at the start. Perhaps a retired IT specialist looking for volunteer opportunities.,"You can also reach the “Georgia Tech OMSCS Social Good” community on google+.  I’m sure you can find volunteers in there. https://plus.google.com/u/0/communities/112812259832378074777 | Thank you, Uvernes. I will pass along this link to my neighbor who is working on this problem with the Department of Corrections here. He is Rich Jacobs ( richjacobs12@gmail.com ). Ultimately a nationwide network of links is needed, available to released prisoners, and for companies and agencies committed to successful reentry into society. The initial step would be developing or expanding what is a available locally to a wider region. Much of what is available may be outdated or limited in scope.",False,2025-01-20 01:04:22.797462,2025-01-20 01:04:22.797462,4bd0c214d68711ef89b40c9a3cb15cde
Which repository helps in acquiring datasets for semantic integration of relational schemas?,https://www.researchgate.net/post/Which_repository_helps_in_acquiring_datasets_for_semantic_integration_of_relational_schemas2?_sg=QLmOrfj3clavHMa60LWWMpsxxrSokoXcT9uplCGpXlVST8Fgjp7ukwTjPrjcqvgKjWzPfQReNM7YZZI,2014-02-01 00:00:00,"UCI repository has one data source for each. However, for semantic integration different datasets from the same domain are sought.,",,False,2025-01-20 01:04:22.821148,2025-01-20 01:04:22.821148,4bd0c214d68711ef89b40c9a3cb15cde
I need to create an easily searchable database of literary motives and book descriptions - which software to use?,https://www.researchgate.net/post/I_need_to_create_an_easily_searchable_database_of_literary_motives_and_book_descriptions-which_software_to_use?_sg=zSWE5QUd353UY739b_gE7f6WmtU8rU7eFlE95qXFMUYuTirconDqpV5zy5xoLbo7qgnudbOMYt_cULw,2016-11-01 00:00:00,"I work on a research project that includes lots of texts, both fictional and life-stories. I need to find a way of arranging my material. Ideally, I would enter  text descriptions into my database with specific tags, and I could then easily search my database. If I would search for 'grandmother', for example, I would get a list of texts that talk about grandmother, etc. Any recommendations for software?","Microsoft Access will be OK | Do you mean ""database"" database, or collection of data? If your data amount is not large, you can even go for a spreadsheet like Excel or Google sheet. For simple application yes MS Access is good. If planing to expand it later to a fully functioning system, use a DBMS like MySQL. | I suggest to use ""Zotero"", it's a powerful software that fits with all your expressed needs. You would also discover some other features, really interesting.  | Elasticsearch could be your perfect option. Elastic search has three main component Elastic search engine,  Logstach and Kibana. Elastic  search  engine will easily digest your text information. The Kibana component is a visualization tool that will allow you search for things quickly. The only issue here is the learning curve to get it installed. Check it out here https://www.elastic.co/products/elasticsearch | You can use either Microsoft Access or MySQL or Oracle. | Considering the size this sounds ripe for Access or even Excel. If you are talking about 100s of thousands of entries with advanced search MySql, PostgreSQL, Sql Server Express (or above if you have licensing), Oracle 11g Express (or above if you have licensing). If you need predictive capabilities above an RDBMS, R. | Access is good and easy to work with. | Microsoft SQL Server is the best  | Based on ten years teaching OCLC, the worldwide accepted online shared cataloging system I totally disagree with all ACCESS suggestions! Find something that is based on the international bibliographic MARC standard. Although it is a very hairy format, it is freely available; in many web apps nowadays. I am bringing up a SpecialLibrary in a nonprofit on something unceremoniously called 'The Library Thing'. I have had my personal book collection on it for ten years. My client will be able to have it for $10 a month. It provides services that large libraries thirty yeers ago paid $50,000 for!One important note: the defaul interface is pretty old and intimidating with alot of scary library-ishstuff on it.  But they recently released a very impressive simplified front end called TinyCat.  And there are many fields where you can put your own information.  Good luck!  | Keep information in plain text files after deciding on a structure, how tags would be represented and so on and search using a free text search tool like Xsearch or AstroGrep. Would be fine for thousands of text files, or markdown.",False,2025-01-20 01:04:22.841219,2025-01-20 01:04:22.841219,4bd0c214d68711ef89b40c9a3cb15cde
Would a database of lectotypes lead to a simplification in taxonomy or to a vast number of lectotypifications from non specialists?,https://www.researchgate.net/post/Would-a-database-of-lectotypes-lead-to-a-simplification-in-taxonomy-or-to-a-vast-number-of-lectotypifications-from-non-specialists?_sg=Su1CiVoSPzK17nt0E_lTLimcAGvyyeD_ltjAhAP4v9CiN-y3SBgpYYkvGzd6EtpqwEv0nUjZXz3k1QM,2014-05-01 00:00:00,"Sometimes it is very hard to find a lectotypification of old taxa. This is very time consumig and frustrating. A database compiling all designated lectotypes could be helpful. On the other hand, the code requires that lectotypification should be made my scientists knowing the taxon and working methods of the author of the taxon for which the lectotypification is done. If it is known that a taxon lacks a specific type this could lead to the automatic lectotypifications described in the code.,So, in the end I would like to have an impression whether in your opinion the disadvatages outbalance the benefits of such a database.,","I totally agree that such a database can not be the place for publication of a lectotypification.On the other hand it could be used to spot taxa which are now lacking a proper typification and thus could be used for ""automatic"" lectotypification. This can be dangerous as someone could typifiy without the understanding of the taxon. Maybe I should specify my concers as I think a database would be very helpful. In some cases one could think that a specimen is type material only on the basis of a collection done by the collector mentioned in the protologue without checking for collection date. Especially collections missing metadata are dangerous and need careful review. Mentioning a specimen as type material or original material is harmless until a lectotype is designated. So compiling specimen of type material or original material, or even of uncertain original material is no problem at all. The step towards a designation of a lectotype, however, needs to be done carefully, as already pointed out. A lectotypification of cause should be done as described. But what if people dont do it? Is this possible confusion worth to have the benefits of easy lectotype information? | Well, since it is hard to find lectotypifications, and if one finds one to be sure it is the oldest one, even if there is a database every user should be aware it probably is not complete, and is just a serious of records of instances that have been found for a taxon, but no-one can guarantee it is complete. So taking such a database as a source to find not-yet lectotypified taxa and start doing so, would be quite unwise. But yes, there will always be the unwise man out there that will start doing such things.People not sticking to the rules is not a real danger; when the database is well managed, such publications can be listed as invalid, and the rest of the world will be aware and won't follow.",False,2025-01-20 01:04:22.869419,2025-01-20 01:04:22.869419,4bd0c214d68711ef89b40c9a3cb15cde
How to make Database management system?,https://www.researchgate.net/post/How-to-make-Database-management-system?_sg=VptNWmRIZHh2gFAUuWzaP9nTElFr3Y1OrGkANujluQe_aCe3t3fqdM-M5UAKcn9w6lWshJLFk2ptdms,2018-11-01 00:00:00,"Hello everyone,I am working on the plankton diversity of freshwater. Other than the research articles, we can make monograph. Recently I knew about database management system (DBMS) and I can make database using my excel data and photograph but i do not how to make database management system? is anybody know about DBMS and how to make online to get everybody access. please share your knowledge.","I do not get what you exactly want. If you have a database already built in excel or access you can make it online by using HTML database. May this link will be helping youhttps://www.w3schools.com/html/html_forms.asphttps://www.w3schools.com/html/html_tables.asp | You usually don't make a DBMS, you USE them.The need for using a DBMS for your problem is a bit ambiguous.In your case if your dataset is not BIG, then you do not even a data base management system. You can use softwares such as Microsoft Access (or its many equivalents) to store and retrieve your data. | I recommend you serach about several systems based on NoSQL databases, such as: graphs databases, value-key store, document store, and other technology oriented to improve the performance when the data are increased.nowadays, the main goal of  DBMS are create solutions for big data problem where it uses and combine the possibilities of five V's of Big data: velocity, volumen, varieity, veracity and visivility. | In my opinion, MySQL, SQLite  would be better for a reliable DBMS | Get in contact with me so that we discus what you want. I can guide you | Data from excel can be imported to the selected DBMS and then made available to other users - depending on the number of users in the two, three or multi-tier architecture.If your photo files exceed 2MB, it is not recommended to store them in the database. One of the older solutions is to keep only the path to the file in the database. However, the application must ensure that access to these files is managed.In this case, if the files are a lot and are large in size, you can consider selected NoSQL database systems. However, solutions well-established on the market for many years, ie MS SQL Server or ORACLE have also come out against new challenges. They are adaptated for storing and managing unstructured data.Both ORACLE and SQL Server allow you to hold binary files outside the database, but the SQL server itself manages these data as if it were stored in a database.SQL Server provides for this purpose the FILESTREAM type in association with FILETABLE, and ORACLE type BFILE.  I think that these are solutions worth considering. | See also the statements of mine and other people on a similar topic  https://www.researchgate.net/post/Can_anyone_recommend_me_a_local_database_software_for_managing_faunistic_data | Since you can store your data in excel file already, it means you are dealing with structured data which makes your problem even simpler. You may use the following guide:1. Database: I recomend the use of MySQL to store your data and use Structure Query Language (SQL) to save and retreive data from it. MySQL can work with Linux & Windows servers. Also, it’s very light and open source....and since you want to make you system accessible online, then you need the following to make a complete system:2. Serverside language: you may choose php, python or pearl etc. Any of this programming languages will help your web pages communicate with the server and your developed database.3. Client-side: If your target is just the basic view, just use basic HTML or XHTML to design your page. Here, you may need to add some few things such as javascript, css etc. to get an advance user viewing experience (which you may not need at this stage).To make your application accessible online after development, you need to communicate with a hosting company to subscribe and also get your own domain if at all you need to have your’s.Hope this helps, good luck.",False,2025-01-20 01:04:22.899717,2025-01-20 01:04:22.899717,4bd0c214d68711ef89b40c9a3cb15cde
How can I do accession number for a DNA sequence using NCBI database?,https://www.researchgate.net/post/How-can-I-do-accession-number-for-a-DNA-sequence-using-NCBI-database?_sg=OJBANdn5yYFnZWuciGdtV54h2kz2TSvgSgPn37JqqKjU48tQbjIP5cYbb1xWMImWLU8hD9Dbkn2md8o,2015-06-01 00:00:00,How can i do accession number for a  fungal DNA sequences using NCBI database?,"Thanks for your kinds, just i am asking about :if i have a  DNA sequence for an important fungal isolate and i need to register it on NCBI database to obtain an accession number for this isolate. | if you have a sequence to be submitted to NCBI, you can use the Sequin software and follow the manual see http://www.ncbi.nlm.nih.gov/Sequin/. | I need list of accession number for my species  | how do i get gene bank accession number of a tested RNA primer sequence?",False,2025-01-20 01:04:22.943042,2025-01-20 01:04:22.943042,4bd0c214d68711ef89b40c9a3cb15cde
 C/T  rs1993116,https://www.researchgate.net/post/C_T_rs1993116?_sg=nFC2nzSHefLF17-6uJjENN8P-CGghfkkHPY3jVmgpsqcZFG5GE40E1LVj5qBp8w6My5TUEUoU7OHrTY,2021-11-01 00:00:00,"In my sequence  result I have   C/T  rs1993116 ,but when I check  the NCBI database I found it A/G what is this mean","The sequence name of rs1993116 is given four ways:CYP2R1 RefSeqGene NG_007936.1:g.8518T>C  GRCh37.p13 chr 11 NC_000011.9:g.14910234A>G  GRCh37.p13 chr 11 fix patch HG873_PATCH NW_003871082.1:g.131174T>C  GRCh38.p13 chr 11 NC_000011.10:g.14888688A>GThe complement sequence of T>C is A>G, so they are looking at one strand or another.  rs1993116 has three derivatives, C;C, C;T and T;T. In this case, they are probably looking at two copies of the chromosome since it is diploid. C/T is probably coming from there. Please correct me if I am wrong.  | Its is A>G. Where did you find see C>T? | اn sequencing  and in some reference also  ",False,2025-01-20 01:04:22.965232,2025-01-20 01:04:22.965232,4bd0c214d68711ef89b40c9a3cb15cde
What is the best OODB theory?,https://www.researchgate.net/post/What_is_the_best_OODB_theory2?_sg=xzIyS9G7fVdam-_8AgnsYVKnX1h39DiLOOFqWOwMAtwEyBDLBAh6Hmn8H0fUb5QsgolpL25iCieJZ_o,2013-05-01 00:00:00,"I need to know the best OODB theory to compare about EASY design and very well to use.,",,False,2025-01-20 01:04:22.984681,2025-01-20 01:04:22.984681,4bd0c214d68711ef89b40c9a3cb15cde
Where do I find an updated address for the dataset NSL KDD ?,https://www.researchgate.net/post/Where_do_I_find_an_updated_address_for_the_dataset_NSL_KDD?_sg=fv8qc-SREoZPKMXZ469wtofHxFriI6iHamrJcpieW1hMVJGSUkYIQfl7NOCayE9b7JJAWHwWpjyCEcA,2015-09-01 00:00:00,"Hello to all of the site ReserchGate, my name is Mauricio Faria and I am a professor and researcher at Universidade Anhembi Morumbi (Laureate) in Brazil. I am looking for a date set known as NSL-KDD but I am having great difficulty. I am designing an experiment with this dataset. The original addresshttp://nsl.cs.unb.ca/NSL-KDD/is no longer available. Unfortunately, this is what appears in the articles. Could Someone provide a link updated or else send by e-mail.","Hi Mauricio,  I think that this link (http://www.shubhamsaini.com/datasets.html) have the dataset. But I'm not sure.Good luck,Daniel | Hello Daniel , thank you. I accessed and downloaded a 3MB file NSL - KDD but it is for the program R. My experiment is to WEKA program. I try to convert. But I'm guessing the size of very small file .Anyway I thank you very much for your help. | I'll look TODAY . Thank you!!!!!! | https://web.archive.org/web/20150205070216/http://nsl.cs.unb.ca/NSL-KDD/ | https://github.com/FransHBotes/NSLKDD-Dataset",False,2025-01-20 01:04:23.004047,2025-01-20 01:04:23.004047,4bd0c214d68711ef89b40c9a3cb15cde
Is there any GUI-based database management system?,https://www.researchgate.net/post/Is_there_any_GUI-based_database_management_system?_sg=vwZDVac25vlnEMdtTmTTF2_gInOJ2Kbe5At3useGxCV8fzCVQs3xpgAigJlSrclzSBqjRoQnsp6u5Pg,2015-06-01 00:00:00,"Actually, I am looking for a DBMS that provides the required graphical user interface for entering and representing pieces of information.,e.g., I want to assign values to some shapes such as triangle, line, circle, etc. Then, I want to assign some values to each of them, their position, connection, etc. I need the software converts the shapes and their relations to data according to the defined algorithms. Then the outcome could be saved in the data base and invoked whenever needed.",,False,2025-01-20 01:04:23.023433,2025-01-20 01:04:23.023433,4bd0c214d68711ef89b40c9a3cb15cde
 C/T  rs1993116,https://www.researchgate.net/post/C_T_rs1993116?_sg=h3Mc1ONpUUkjGFQU9tu1IzNsD8Jf-AFV1zeJbXVAJgeYSWMezTyRNF021fVXVweyc-Vv3JKutOVghBg,2021-11-01 00:00:00,"In my sequence  result I have   C/T  rs1993116 ,but when I check  the NCBI database I found it A/G what is this mean","The sequence name of rs1993116 is given four ways:CYP2R1 RefSeqGene NG_007936.1:g.8518T>C  GRCh37.p13 chr 11 NC_000011.9:g.14910234A>G  GRCh37.p13 chr 11 fix patch HG873_PATCH NW_003871082.1:g.131174T>C  GRCh38.p13 chr 11 NC_000011.10:g.14888688A>GThe complement sequence of T>C is A>G, so they are looking at one strand or another.  rs1993116 has three derivatives, C;C, C;T and T;T. In this case, they are probably looking at two copies of the chromosome since it is diploid. C/T is probably coming from there. Please correct me if I am wrong.  | Its is A>G. Where did you find see C>T? | اn sequencing  and in some reference also  ",False,2025-01-20 01:04:23.042478,2025-01-20 01:04:23.042478,4bd0c214d68711ef89b40c9a3cb15cde
Recently I cannot access to NCBI and PubMed. Does anybody experience this situation?,https://www.researchgate.net/post/Recently_I_cannot_access_to_NCBI_and_PubMed_Does_anybody_experience_this_situation?_sg=WMoD2OIR7Tb5Zh3RnVcZ8ZjOg-koNf4Uz6c24sn4QydHo9gDQ4y_4YJ1rMPO34kxved4aih8q_vOwMA,2013-05-01 00:00:00,"If you know new things please share them with me.,http://www.ncbi.nlm.nih.gov/","Update the DNS to 8.8.8.8 as primary and 8.8.4.4 as secondary.This should fix the problem | NCBI comes up for me as does PubMed | Same I am not able to acess from home (Time fibre optic connection),working from university is fine, looking for options to make it work. | I also can't access from my computer, but no problem from others. I have an old mac, I use firefox and/or chrome and both not working. My internet connection is otherwise absolutely fine. I think it depends on the computer somehow but don't know how to fix it (I hardly find anything about it on the internet too).  | Update the DNS to 8.8.8.8 as primary and 8.8.4.4 as secondary.This should fix the problem | YES!! Thank you!!! | can some one give me help ? | Recently Pubmed have added a recommendation of ""new pubmed"" to use. may be you have clicked on it. it doesn't work and then, you can't use pubmed. you have two approach. First, you can use another web browser (like firefox, opera, ...) that you haven't used it to browse pubmed before. the second way is deleting all of browsed data and history, then you can use pubmed again, but be aware of clicking on the ""new pubmed"" again! | hello, is it a universal problem, or is it related to Iran sanctions? Ehsan Beigzadeh  | Tried the above still locked out.",True,2025-01-20 01:04:23.061359,2025-01-20 01:04:23.061359,4bd0c214d68711ef89b40c9a3cb15cde
How MYSQL database can be linked to an HTML code ?,https://www.researchgate.net/post/How-MYSQL-database-can-be-linked-to-an-HTML-code?_sg=m5bHBl0Q7biAWvM26V76uH7lPFowCkO7WhEQJPSMthrHBhnv0o_rp39WUTt0obed03jFRbiwaTVydF4,2015-01-01 00:00:00,We have developed a HTML web page. We have to incrporate a MYSQL database into that. Can anybody tell how to do this ?,"https://coolestguidesontheplanet.com/how-to-connect-to-a-mysql-database-with-php/ | As far as I know to link web page to MySQL people usually use PHP to connect. there are lot of tutorial for that in web. try that Ankithttp://www.w3schools.com/php/php_mysql_connect.asp | There are several ways. Even Javascript today has bindings to access mysql database. The usual is you use a server-side language to connect to database, similar what Bharathi mentioned, but you can choose the language, not only PHP. Also, if using PHP, I would recommend using and ORM for the connection, like Doctrine, not connecting through PHP itself directly. My company works with consulting. If you have interest we can help you on that. | HTML not directly connect to db but you can try some scripting languages for example ASP, PHP, PERL, JavaScript | I usually use PhP. You can check www.w3schools.com/php/php_mysql_intro.asp | This is only possible with the use of scripting languages. Embedding this scripting language on your HTML code will enable you to make this connection to your desired database. Example of them are PHP, ASP, Javascript etc. | As forespeakers mentioned the best way is to use one of the server-side scripting languages, PHP is quite commonly used for that purpose, but APS might turn easier to implement (especially if working with Windows server). | Yes, bro u can crack it. from Perl or PHP n Javascript.  | https://www.w3schools.com/php/php_mysql_connect.asp | https://coolestguidesontheplanet.com/how-to-connect-to-a-mysql-database-with-php/",True,2025-01-20 01:04:23.085229,2025-01-20 01:04:23.085229,4bd0c214d68711ef89b40c9a3cb15cde
When should one choose XML storage or a relational model?,https://www.researchgate.net/post/When_should_one_choose_XML_storage_or_a_relational_model?_sg=XbfpmRyiSGofUc-apmbnj3d7E957nWta8VdXkMJrdSZIZ1iPJh_qjoXvhmBDnmloC8LLNz_MyZ1QwGI,2015-03-01 00:00:00,what is their differences and when we should use xml databases instead of relational databases?,"Agree with Rodrigo Gonzalo Parra. When the data structure is flexible or heterogeneous or hard to definition in a relational schema (i.e. each tuple have one different structure; incomplete or irregular - e.g. the bibtex data). XML is a semi-structured data. | XML is a language that hierarchically orders your data. You can have an entity and then the whole information about it can be ordered in the file by using different tags.A relational database on the other side have a internal structure where the different objects have different attributes and the information is stored as less redundantly as possible and you have the relational algebra language that allows you to manipulate the data very quickly. I would suggest you to use a relational database if your data is too big. It will allow to handle it really quickly and also it will be easy to link it to a web server in the future. You can have certain parts of your data in the xml format and link it to your relational database just by adding an attribute with the physical location of the files in the server's disk | Agree with Rodrigo Gonzalo Parra. When the data structure is flexible or heterogeneous or hard to definition in a relational schema (i.e. each tuple have one different structure; incomplete or irregular - e.g. the bibtex data). XML is a semi-structured data. | Relational databases are generally structured one, so you need to define everything in advance, like its schema, all the data types of the value you are going to store and so on. whereas XML is a semi-structured so you may have little flexibility in storing and representing your data, you may make changes very easily in XML as compared to RDBMS. But the biggest advantage of RDBMS is the ease of generating relations. So it depends on applications, whether it want better flexibility or better relationships. | Nowadays XML is used in many web-services, so it has become popular as Web Database. | Hi,well, choosing between a relational storage or an XML storage depends on the nature of your data: if yoru data are fully structured, respecting a pre-defined schema, the relational data is the best, among others because of the maturity of existing relational tools. If your data are semi-structured or not structured at all, and if it has a hierarchical structure, XML can be used, even if you data is schemaless.Besides, some (R)DBMSs, for instance Oracle, allow you to combine and make advantage of the flexibility of XML on the one hand and of the maturity of SQL. Many stirage modes are available and theyr are fully explained in the related documentation. | In addition to things said above, XML was classically designed to make data portable on the web, whereas relational databases are an infrastructure to store data in one place. For that purpose, JSON is used more nowadays, because XML is a quite ""heavy"" format due to it's self descriptiveness. In my opinion, if your data is not strongly hierarchically structured, a relational database is probably the way to go (PostGresQL for example is a very good and free relational system) | I would use XML like when I need to do data exchange between two systems e.g. an integration of two different systems but then that is temporary like when waiting for the other system to process some data then you pick it up and do processing on your end after which all the two systems should find a way of deleting the XML files used during data interchange. RDBMs come in hand for long term storage of data and processed information. My 2 cents though. | People abuse XML storage in many cases where relational model is the right one. The fact that HTML5 is XML does not enforce storing data as XML in the database. In fact XHTML can easily be generated fro the relational structure and if you receive XML from an external source, it can easily be stored in a relational database if the data structure allows it. XSLT and/or XQuery can extract the data. XML storage is needed if you have to store nodes of too different structures. In such a case you also need an XML-aware database software. You must be able to modify a node anywhere in the middle of the tree without the necessity of reading and writing the whole XML document. | I agree with the other answers. It's probably best to go with a relational model unless you consider that:* the model has lots of nesting - that means a lot of tables in a relational model, but that's not necessarily a reason to use XML* the model is very changeable or incomplete or not regimented - you can still cope with this in a relational setting* the model is a meta-model - not low level data really. XML is very good at describing data about data.* the model is recursive - not necessarily a compelling reason to use XML on its own* you'd like to take advantage of name spacing to include instances of other XML schema at the data level* the amount of data is not large - transporting and processing XML is resource hungry. The memory imprint of a DOM is typically 10x the size of the source file; it can be very verbose. You can use an XML database though: e.g. exist-db.org* the data does not have to be in a different structure - transforming can be expensive.XML for data interchange? (Joseph Mwema, Doulkifli Boukraâ) Certainly. XML for model transformations? That works.",False,2025-01-20 01:04:23.108454,2025-01-20 01:04:23.108454,4bd0c214d68711ef89b40c9a3cb15cde
I am an university database teacher. What is better...to teach relational model before data modelling or viceversa? I like to know your opinions.,https://www.researchgate.net/post/I_am_an_university_database_teacher_What_is_betterto_teach_relational_model_before_data_modelling_or_viceversa_I_like_to_know_your_opinions?_sg=jGqb4YbctNFMqI1BHCsXh6OspTzLAwVjg4EncMlD1Hi_Jd4miQfh4mxMqnQWsx_8ZuVwHEtAm7QbLgc,2013-05-01 00:00:00,"?????,",,False,2025-01-20 01:04:23.140420,2025-01-20 01:04:23.140420,4bd0c214d68711ef89b40c9a3cb15cde
How to download all the bacterial protein data from NCBI?,https://www.researchgate.net/post/How-to-download-all-the-bacterial-protein-data-from-NCBI?_sg=96r38Jc9EB1DoWFq73fsojOzqPxXBgXto7uqX_QwluIvBtsqRrNGsLkcVIBa_bA2j8BGdtklKlrqJXE,2013-08-01 00:00:00,"I want to do a local blast using all the bacterial protein data from NCBI instead of NR. Is there any way to download all the data from NCBI? Or to filter the NR database locally?,","Try this perl script. It uses NCBI EUTILS webservice.Run it like: perl ncbi_fetch.pl > bacteria_prot.fastaIt will ask for database, choose: proteinIt will ask for Entrez query, write: txid2[Organism:exp]It will ask for format: choose: fasta There are almos 63 million bacterial proteins on Genbank. It will run for days, so be patient. The entrez query specified returns all records under bacteria taxonomy id. You could use this script with other queries or tweak the script if it stops download at the same pointThe follows the perl script:#!/usr/bin/perl -w#Gustavo Gilson Lacerda Costa ( glacerda@lge.ibi.unicamp.br)#29/2/2008 (uses NCBI webservices)#Based on www.ncbi.nlm.nih.gov/entrez/query/static/eutils_example.pl#Usage: perl ncbi_fetch.pl > output_fileuse LWP::Simple;my $utils = ""http://www.ncbi.nlm.nih.gov/entrez/eutils"";my $db     = ask_user(""Database"", ""nuccore|nucest|protein|pubmed"");my $query  = ask_user(""Query"",    ""Entrez query"");my $report = ask_user(""Report"",   ""fasta|genbank|abstract|acc"");my $esearch = ""$utils/esearch.fcgi?"" .""db=$db&usehistory=y&term="";my $esearch_result = get($esearch . $query);$esearch_result =~ m|<Count>(\d+)</Count>.*<QueryKey>(\d+)</QueryKey>.*<WebEnv>(\S+)</WebEnv>|s;my $Count    = $1;my $QueryKey = $2;my $WebEnv   = $3;print STDERR ""Count = $Count; QueryKey = $QueryKey; WebEnv = $WebEnv\n"";my $retstart=0;my $retmax=1000;while ($retstart<$Count) {   my $efetch = ""$utils/efetch.fcgi?"" .               ""rettype=$report&retmode=text&retstart=$retstart&retmax=$retmax&"" .               ""db=$db&query_key=$QueryKey&WebEnv=$WebEnv"";   print STDERR ""RETRIEVING $retmax results starting at result $retstart\n"";  my $efetch_result = get($efetch);  my $copy=$efetch_result;  my $countSeqs=0;  if ($report eq 'fasta') {	  $countSeqs= $copy =~ tr/\>//;  } elsif ($report eq 'genbank') {	  $countSeqs = $copy =~ tr/\/\///;  } elsif ($report eq 'acc') {	$countSeqs = $copy =~ tr/\n//;  }  my $expected=$retmax;  if ($retstart>$Count-$retmax) {	$expected=$Count-$retstart;  }  if ($countSeqs>=($expected-1000)) {	print ""$efetch_result"";	$retstart+=$retmax;  } else {	print STDERR ""ERROR...TRYING AGAIN ($countSeqs / $expected)\n"";  }}sub ask_user {  print STDERR ""$_[0] [$_[1]]: "";  my $rc = <>;  chomp $rc;  if($rc eq """") {      die ""Error: Empty field: $_[0]\n"";  }  return $rc;} | Try this perl script. It uses NCBI EUTILS webservice.Run it like: perl ncbi_fetch.pl > bacteria_prot.fastaIt will ask for database, choose: proteinIt will ask for Entrez query, write: txid2[Organism:exp]It will ask for format: choose: fasta There are almos 63 million bacterial proteins on Genbank. It will run for days, so be patient. The entrez query specified returns all records under bacteria taxonomy id. You could use this script with other queries or tweak the script if it stops download at the same pointThe follows the perl script:#!/usr/bin/perl -w#Gustavo Gilson Lacerda Costa ( glacerda@lge.ibi.unicamp.br)#29/2/2008 (uses NCBI webservices)#Based on www.ncbi.nlm.nih.gov/entrez/query/static/eutils_example.pl#Usage: perl ncbi_fetch.pl > output_fileuse LWP::Simple;my $utils = ""http://www.ncbi.nlm.nih.gov/entrez/eutils"";my $db     = ask_user(""Database"", ""nuccore|nucest|protein|pubmed"");my $query  = ask_user(""Query"",    ""Entrez query"");my $report = ask_user(""Report"",   ""fasta|genbank|abstract|acc"");my $esearch = ""$utils/esearch.fcgi?"" .""db=$db&usehistory=y&term="";my $esearch_result = get($esearch . $query);$esearch_result =~ m|<Count>(\d+)</Count>.*<QueryKey>(\d+)</QueryKey>.*<WebEnv>(\S+)</WebEnv>|s;my $Count    = $1;my $QueryKey = $2;my $WebEnv   = $3;print STDERR ""Count = $Count; QueryKey = $QueryKey; WebEnv = $WebEnv\n"";my $retstart=0;my $retmax=1000;while ($retstart<$Count) {   my $efetch = ""$utils/efetch.fcgi?"" .               ""rettype=$report&retmode=text&retstart=$retstart&retmax=$retmax&"" .               ""db=$db&query_key=$QueryKey&WebEnv=$WebEnv"";   print STDERR ""RETRIEVING $retmax results starting at result $retstart\n"";  my $efetch_result = get($efetch);  my $copy=$efetch_result;  my $countSeqs=0;  if ($report eq 'fasta') {	  $countSeqs= $copy =~ tr/\>//;  } elsif ($report eq 'genbank') {	  $countSeqs = $copy =~ tr/\/\///;  } elsif ($report eq 'acc') {	$countSeqs = $copy =~ tr/\n//;  }  my $expected=$retmax;  if ($retstart>$Count-$retmax) {	$expected=$Count-$retstart;  }  if ($countSeqs>=($expected-1000)) {	print ""$efetch_result"";	$retstart+=$retmax;  } else {	print STDERR ""ERROR...TRYING AGAIN ($countSeqs / $expected)\n"";  }}sub ask_user {  print STDERR ""$_[0] [$_[1]]: "";  my $rc = <>;  chomp $rc;  if($rc eq """") {      die ""Error: Empty field: $_[0]\n"";  }  return $rc;} | thanks,Costa. | FASTA BLAST databases {formatdb before use w/BLAST} & Protein Clusters at http://www.ncbi.nlm.nih.gov/guide/proteins/ | Hi Costa, Thanks for the script. its working, but it got stuck at1959000 sequence. It shows, its still in process but from last 3 days, this number is not changing. Any suggestions? Thanks in advance. ",False,2025-01-20 01:04:23.161528,2025-01-20 01:04:23.161528,4bd0c214d68711ef89b40c9a3cb15cde
I would like to know good free satellite image data site for download,https://www.researchgate.net/post/I_would_like_to_know_good_free_satellite_image_data_site_for_download?_sg=6jVHTqvx_iESYWSzRl82lHwbz5MFG2PoX1L7L9Axa-VoS59Vy422OHVZafkMnVSZVW0dcpkjXpSq4Oo,2012-03-01 00:00:00,"I need DEM, NDVI, maximun and minimum Land surface temp, precepitaion humidity if available is asian region looking for 30 m or less spatial resolution around 2009,",Usgs.com     ; landsat.com,False,2025-01-20 01:04:23.188080,2025-01-20 01:04:23.188080,4bd0c214d68711ef89b40c9a3cb15cde
SCI database search,https://www.researchgate.net/post/SCI_database_search?_sg=OvnLQiEz123JPYEk07NF5TDsN6AJsj_7xmAKDG-yMdVjcDwaIv3GEGHrvoVCmjRUOdiUyD-02QMXuEs,2022-02-01 00:00:00,"One question related to science database search. I want to search SCI database to verify if paper  is indexed or not. I searched through web of science, and as result I get one of my paper but does this mean that it s indexed in SCI database? thx, any comments are welcome.","The Science Citation Index is accessed through the Web of Science platform, with which more databases can be searched simultaneously. To search the Science Citation Index individually use the More Settings option at the foot of the Web of Science search screen.https://www.google.com/search?sxsrf=APq-WBvOvRywcZe3f9jsZ4WTRF8NfcCkmA:1646895914200&q=How+do+I+find+the+SCI+index?&tbm=isch&source=iu&ictx=1&vet=1&fir=4mYR8GjR53R9MM%252COR5UbcqbtTsT0M%252C_&usg=AI4_-kT2QvIlLm-tQYN0Bci-YuTB8RFOdQ&sa=X&ved=2ahUKEwjeqMqv_br2AhXeSWwGHe4wCd0Q9QF6BAgVEAE#imgrc=4mYR8GjR53R9MM",False,2025-01-20 01:04:23.210157,2025-01-20 01:04:23.210157,4bd0c214d68711ef89b40c9a3cb15cde
Database design,https://www.researchgate.net/post/Database-design?_sg=-Eqp3stm-kk5IS_F2zyxymVS8878DfroHlf8oicKa1gaPNOwXWpkpcArpsrAMBeyj4O6PECdwqeBci4,2012-12-01 00:00:00,"Suppose we are trying to design a database. Will it be good if we create a table within a table? Or is it better to create each table individually? Why?,","Can you define what you mean by a ""table within a table""?The trivial answer is that separate tables are more flexible, while conjoined tables are more thrifty under certain conditions, making the answer dependent on what you want to optimize.The trivial answer may not be applicable, for some definitions of ""table with a table"". | ""Table withihn a Table"" idea is not clear to me.It is good to group similar attributes in a table and separate distinct attributes in different table. You need to Normalize data for a good Database design. | I mean nested table ie a column of a tabla itself is a table having attributes and value. | I'm afraid that's still not clear to me, though I'll admit that I may be too far from modern database design to comprehend.I don't understand how a column could contain a table.  If you mean that a column ""contains other columns"", then that's not so much ""contains"", as extra columns in the main table.  If that's what you mean, then M. Haque's answer applies - in general, if that design results in a normalized set of tables, it's good, if it doesn't, it probably can be improved.If, instead you mean that a value stored in a cell in a table could be another table, in general I believe this is provably a poor design, with the possible exception of cases where that ""stored table"" data is only read, and never searched.  In this latter case, the ""stored table"" is a ""blob"" data type, and it's irrelevant that it can be interpreted as a table, external to the database.  If you need to treat the ""stored table"" as a table, and access/search its contents, then storing it in a cell in another table is going to defeat the features your database has for searching things efficiently.There's a possible caveat to this, in that it's at least conceptually possible to design an object oriented database that wouldn't fail in this fashion, but object oriented database paradigms are not particularly mature, and their theoretical capabilities often outstrip their practical limitations.",False,2025-01-20 01:04:23.229698,2025-01-20 01:04:23.229698,4bd0c214d68711ef89b40c9a3cb15cde
Can anyone recommend references (especially archaeological) on old quarries and open pits from Hunedoara county?,https://www.researchgate.net/post/Can_anyone_recommend_references_especially_archaeological_on_old_quarries_and_open_pits_from_Hunedoara_county?_sg=_FzB71inAbqeuhIae6u7-06XCTBxL6m6nnIo195zHh1G2rAXHyUhalvaaJhGhNxKS6al6f233a1OlUA,2014-04-01 00:00:00,"It is very difficult to do surface mining statistics because old data are missing.,",,False,2025-01-20 01:04:23.255833,2025-01-20 01:04:23.255833,4bd0c214d68711ef89b40c9a3cb15cde
Is there any GUI-based database management system?,https://www.researchgate.net/post/Is_there_any_GUI-based_database_management_system?_sg=gyCuLnk3vFVZAUWP-ISPoxNACquuLOCs2FiMDGO3OM5ckt144fLd24xWG0UtK1Xyajcp1yN0H9q7CqM,2015-06-01 00:00:00,"Actually, I am looking for a DBMS that provides the required graphical user interface for entering and representing pieces of information.,e.g., I want to assign values to some shapes such as triangle, line, circle, etc. Then, I want to assign some values to each of them, their position, connection, etc. I need the software converts the shapes and their relations to data according to the defined algorithms. Then the outcome could be saved in the data base and invoked whenever needed.",,False,2025-01-20 01:04:23.272675,2025-01-20 01:04:23.272675,4bd0c214d68711ef89b40c9a3cb15cde
How can I get DDSM database?,https://www.researchgate.net/post/How-can-I-get-DDSM-database?_sg=ubsRRtbWMx12io3MMFgC2iRu9T-_hsDFvYFqErWfxjEGq9zv4PYbVGFaPAYpZAs4gq67Nf7skDkPY7A,2015-11-01 00:00:00,"Need DDSM database in readable format please.,Can't find any link to download it !",Thanks for the link,False,2025-01-20 01:04:23.289363,2025-01-20 01:04:23.289363,4bd0c214d68711ef89b40c9a3cb15cde
I’m looking to find the Computer Database title. Please anyone can help me to find a title to make a research on it? ,https://www.researchgate.net/post/Im-looking-to-find-the-Computer-Database-title-Please-anyone-can-help-me-to-find-a-title-to-make-a-research-on-it?_sg=7NsORceTF6HcMVeYzWN8RlZHyMaAm-1u9nl_UuFqPUzjwrbK-NwJIFGlZfCE-8iPwwGpQGUGnSnFJSQ,2018-03-01 00:00:00,"I wanna make a comparison between the past and present of the title.,Also, I wanna make a survey for the title. how you can help mt to suggest the title?","Dear  Mohammed Qader Kheder,Look the link maybe helpful for you.http://solutions.cengage.com/Gale/Database-Title-Lists/?cid=14W-RF0329&iba=14W-RF0329-8%22%20%5Ct%20%22_blankRegards, Shafagat | Dear Prof,Try this title "" Comparison of <Existing Methods> with <Proposed Method> using<Algorithm Name>  | Try this portal: http://www.title-generator.comjust put the keywords, and you will receive many suggestions... if you choose your keywords carefully the titles will be more relevant | Big data//////IOT | NoSQL database (performance, mapping, etc) | Preference queries  | You can try adhoc database | Ask yourself, what are You try to research and maybe what are you know about the purpose.",False,2025-01-20 01:04:23.311361,2025-01-20 01:04:23.311361,4bd0c214d68711ef89b40c9a3cb15cde
Azure database system in microsoft teams app?,https://www.researchgate.net/post/Azure_database_system_in_microsoft_teams_app?_sg=o3IHlegDXCNBLq5_AB8RmZFxLmhGSibnPXvvvXnvpEtxZvQaGNL48L8VL7hh7hCAM4s1yVE-9WSZ98g,2024-10-01 00:00:00,"i need diagram of satabase structure and relational diagram,","Integrating an Azure database system with a Microsoft Teams app allows organizations to leverage data storage, retrieval, and analytics directly within the collaborative environment of Teams. This setup can support custom apps, bots, or dashboards that use the Azure database to store and manage data.Here’s how you can achieve this integration:1. Choose the Right Azure DatabaseDepending on your use case, you can choose from the following Azure databases:Azure SQL Database:      For relational data and transactional workloads.Azure Cosmos DB:      For globally distributed, scalable NoSQL data.Azure Table Storage:      For simple key-value store scenarios.Azure Data Lake:      For large-scale data analytics.Azure Database for PostgreSQL/MySQL: For open-source relational databases.2. Develop the Teams AppTeams apps are built using the Microsoft Teams Developer Toolkit and consist of the following components:Tabs:      Embedded web experiences.Bots:      Interactive chat agents.Messaging Extensions:      Allow querying and inserting data into chats.Webhooks and Connectors: For sending notifications.You can host your Teams app backend on Azure App Service, Azure Functions, or other Azure compute options.3. Connect the Azure Database to Your AppUsing SDKs and APIs:      Azure databases offer SDKs (e.g., Python, Node.js, .NET) and REST APIs to      interact with the database.Connection Strings:      Securely store your database connection string in Azure Key Vault     or environment variables.Authentication:      Use Azure Active Directory (AAD) for secure user authentication.4. Integrate with TeamsAzure Bot Service:      If you’re building a bot, connect it to Teams using the Microsoft Bot      Framework and integrate the database for dynamic interactions.Custom Tabs:      Create a web app that connects to the Azure database and embeds it as a      tab in Teams using an iframe.Adaptive Cards:      Display real-time data from your Azure database in chats or channels via      interactive cards.5. Ensure Security and ComplianceRole-Based Access Control (RBAC): Use Azure's RBAC to manage who can access or modify      the database.Data Encryption:      Ensure that data in transit and at rest is encrypted.Compliance:      Adhere to organizational and regulatory data compliance standards (e.g.,      GDPR, HIPAA).6. Testing and DeploymentTeams App Testing:      Use the Teams Developer Portal for testing your app.Azure Deployment:      Use tools like Azure DevOps or GitHub Actions for continuous integration      and deployment (CI/CD).Example Use CaseImagine a ticketing system:Frontend:      A Teams bot that allows users to submit and view tickets.Backend:      Hosted on Azure Functions, which writes ticket data to an Azure SQL      Database.UI: A      custom Teams tab that displays tickets using data queried from the      database.",False,2025-01-20 01:04:23.335578,2025-01-20 01:04:23.335578,4bd0c214d68711ef89b40c9a3cb15cde
How to detect anomalous access in relational database?,https://www.researchgate.net/post/How-to-detect-anomalous-access-in-relational-database?_sg=NSrOI2vcXPLA1T8OfP4fVmv0TzEwEFC5_-ba36oDOtumeEInC6_C4l9MwskX0lYMna47NG85UagQLjo,2013-11-01 00:00:00,"I have two issues regarding the question above. First, how to identify anomaly in RDBMS? Second, how to detect anomalous query in the same?,",,False,2025-01-20 01:04:23.361837,2025-01-20 01:04:23.361837,4bd0c214d68711ef89b40c9a3cb15cde
What do you use to maintain a sane reference database?,https://www.researchgate.net/post/What-do-you-use-to-maintain-a-sane-reference-database?_sg=deTJak2PEKABMckoHBzR83l-LFhfbSwOKobOp80nEA4ROXm64F0oY1cjVA2pZGbeoUMVGfUxnTiITUM,2014-02-01 00:00:00,"EndNote? CiteULike? Web of Science's user profile? A homespun utility? Database Excel? Because a pile of paper or a byzantine digital folder tree filled with PDFs doesn't cut it any more.,",,False,2025-01-20 01:04:23.380400,2025-01-20 01:04:23.380400,4bd0c214d68711ef89b40c9a3cb15cde
Are there any specific algorithms done to prevent json attacks in nosql databases?,https://www.researchgate.net/post/Are_there_any_specific_algorithms_done_to_prevent_json_attacks_in_nosql_databases?_sg=7rftkapjNek0z_aYAzyF1pu9M75et6Ghir7DnWo12LXyP9hy8AIxPNCl55YVb6yjYWa7GhJTd4oQkmM,2014-05-01 00:00:00,"I am doing a research in security of nosql database., I started to read aboout json attacks and still can't find any specific work regarding nosql databases.,",,False,2025-01-20 01:04:23.399184,2025-01-20 01:04:23.399184,4bd0c214d68711ef89b40c9a3cb15cde
How can I copy too a created sqlite database in android device SDCard?,https://www.researchgate.net/post/How_can_I_copy_too_a_created_sqlite_database_in_android_device_SDCard?_sg=0vdFazDXDVVEuCjk4dEqNVrXXrIf1WoU4Kmk_Cu79NVy5PL0zIcq8Mje0j2DE8ux_bRtCWpJeVoo4FY,2015-01-01 00:00:00,I created a sqlite database using with SQLite manager for browser. I now want to copy it to a device SDCard. If someone has sample code showing how to copy sqlite database to SDCard please can you help me?,"For the database that you want to copy, use some explorer to copy it as you normally do with any other type of file, and then remember the address to access it internally later. Remember that the applications databases are handled internally by Android, others externals by the user.You can send any file to your device using USB cable or wifi, Bluetooth, etc. | In funny words, using your finger:) but Nikolaos and Oscar have right:)",False,2025-01-20 01:04:23.420536,2025-01-20 01:04:23.420536,4bd0c214d68711ef89b40c9a3cb15cde
Do you think that the NoSQL databases that do not strongly follow ACID properties may have limited usage in the future?,https://www.researchgate.net/post/Do-you-think-that-the-NoSQL-databases-that-do-not-strongly-follow-ACID-properties-may-have-limited-usage-in-the-future?_sg=PGDfcOfEkTXkP3HKatXcPg36iUmi9LS2Rz3MzFzVz0DiGG8RYsILfUf7j7dn-40T-xNx1B3lGf5jyPc,2015-01-01 00:00:00,"NoSQL is highly valued for consistency, but is not strong enough to fit a set of ACID properties.","I think for transactional systems , ACID will be core. But for OLAP kind of systems , transaction , integrity will not so important.You might want to look at CAP theoremhttp://en.wikipedia.org/wiki/CAP_theorem. | I will agree with Saptarsi Goswami.The NoSQL databases are having and will have their own niche in the database world. The main focus of the NoSQL remain the same: (a) rapid solution creation (when the NoSQL is faster for utilization); (b) absence of the strict data integrity and tolerance to the some data lost, (c) the absence of the strict schema (or schema """"on the fly""), etc. | I think that in the near future they will have to deal with some sort of consistency issues specially for critical applications. Most business databases (transactional) works with strong consistency but lack the high performance of NoSQL databases. Trading of performance with consistency is not a solution. some attempts have been done to add transactions to NoSQL databases such as http://www.vldb.org/pvldb/vol6/p1434-dey.pdf in VLDB2013. I believe it will come to a point in the future that there will be transactions (consistency) without losing the high performance of NoSQL databases. | NoSQL Systems mainly focus on BASE theorem. As, consistency is compromised to maintain scalability. NoSQL systems are come into database world, because of big data storage. | You might be interested on this video of Dave Rosenthal from FoundationDB: NoSQL and ACID: http://youtu.be/1KsZKRcgmuU",False,2025-01-20 01:04:23.439954,2025-01-20 01:04:23.439954,4bd0c214d68711ef89b40c9a3cb15cde
I have an idea to improve performance of current real time commit protocols. Will anyone help me with performance study part of my work?,https://www.researchgate.net/post/I_have_an_idea_to_improve_performance_of_current_real_time_commit_protocols_Will_anyone_help_me_with_performance_study_part_of_my_work?_sg=_HfvSLf0-HQmUJ1KGJoB3wMk_b9s4NXlBMv0Xa56UELew24byRjceQ7scA4hikXa-Tv_5vesCbh_iAI,2016-03-01 00:00:00,"Commit protocol for DRTDBS,I am currently working to develop a new real time commit protocol for distributed real time database system.I need a help for simulation study of my work..",,False,2025-01-20 01:04:23.462840,2025-01-20 01:04:23.462840,4bd0c214d68711ef89b40c9a3cb15cde
Do you think that the NoSQL databases that do not strongly follow ACID properties may have limited usage in the future?,https://www.researchgate.net/post/Do-you-think-that-the-NoSQL-databases-that-do-not-strongly-follow-ACID-properties-may-have-limited-usage-in-the-future?_sg=RLFjPenlZdf7DooLU_-7SmdO2GED14aDMQBckBG3f1FCL7PTqQH8I6WoP5bRLLFzNtXNxihasSozRRo,2015-01-01 00:00:00,"NoSQL is highly valued for consistency, but is not strong enough to fit a set of ACID properties.","I think for transactional systems , ACID will be core. But for OLAP kind of systems , transaction , integrity will not so important.You might want to look at CAP theoremhttp://en.wikipedia.org/wiki/CAP_theorem. | I will agree with Saptarsi Goswami.The NoSQL databases are having and will have their own niche in the database world. The main focus of the NoSQL remain the same: (a) rapid solution creation (when the NoSQL is faster for utilization); (b) absence of the strict data integrity and tolerance to the some data lost, (c) the absence of the strict schema (or schema """"on the fly""), etc. | I think that in the near future they will have to deal with some sort of consistency issues specially for critical applications. Most business databases (transactional) works with strong consistency but lack the high performance of NoSQL databases. Trading of performance with consistency is not a solution. some attempts have been done to add transactions to NoSQL databases such as http://www.vldb.org/pvldb/vol6/p1434-dey.pdf in VLDB2013. I believe it will come to a point in the future that there will be transactions (consistency) without losing the high performance of NoSQL databases. | NoSQL Systems mainly focus on BASE theorem. As, consistency is compromised to maintain scalability. NoSQL systems are come into database world, because of big data storage. | You might be interested on this video of Dave Rosenthal from FoundationDB: NoSQL and ACID: http://youtu.be/1KsZKRcgmuU",False,2025-01-20 01:04:23.483244,2025-01-20 01:04:23.483244,4bd0c214d68711ef89b40c9a3cb15cde
What are  different heuristic available to optimize the query in centralized database?,https://www.researchgate.net/post/What_are_different_heuristic_available_to_optimize_the_query_in_centralized_database2?_sg=w6KofOYYBHZaGvC-iVhpC-p7Cf-3FPtsOoaN698bTLYemSUps-FtQJ2MmeM2DQdGz14VUdzPwKwWKLY,2014-01-01 00:00:00,"I need different heuristics for query optimization.,",,False,2025-01-20 01:04:23.500747,2025-01-20 01:04:23.500747,4bd0c214d68711ef89b40c9a3cb15cde
What issues are important to you related to information processing in Big Data database systems?,https://www.researchgate.net/post/What_issues_are_important_to_you_related_to_information_processing_in_Big_Data_database_systems?_sg=6jWPBHpmWSxnJBF5Okew2-wWUVnxjJkS6fImIx7fS3NIaUjN25ehPssevuXo-WVtCAn6R4xy2_dMdGw,2018-11-01 00:00:00,"What are the important issues for you related to the collection and processing of large information sets inBig Datadatabase systems?,,The current technological revolution known asIndustry 4.0is motivated by the development of the following factors:,-Big Datadatabase technologies,,- cloud computing,,- machine learning,,- Internet of Things,,- artificial intelligence.,On the basis of the development of the new technological solutions mentioned in recent years, the processes of innovatively organized analyzes of large collections of information collected inBig Datadatabase systems dynamically develop.,In my opinion, the fastest-growing business projects are primarily those that are the subject of innovative startups developing dynamically for a minimum period of several years. Startups developinnovative business projectsin such areas as: information technology, ICT, Internet, biotechnology, energy, ecology, environmental protection, medicine, agribusiness, etc. In addition, a number of innovative technologies in construction, material, process and marketing innovations have recently been created in the field of smart city, life science, cleantech, medical intelligence and others that are used by companies and corporations operating in various sectors of thenational or international economy.,In addition, innovative business projects are also developed in the fields of various fields of information services, advanced data processing, business analytics and the development of teleiform technologies, which together are the pillars of a knowledge-based economy. The current technological revolution known as Industry 4.0 is motivated by the development of the following factors:,Big Data database technologies, cloud computing, machine learning, Internet of Things, artificial intelligence. It is anticipated that in the next years in these fields of science and technology many large startups will be created, which will be developed effectively based on innovative business projects related to the topics mentioned above. On the basis of the development of the new technological solutions mentioned in recent years, the processes of innovatively organized analyzes of large information collections gathered inBig Data database systemsdynamically develop.,In each of these areas, many specific design topics can be distinguished, in which business startups develop and reach the minimum level of a medium-sized company or large corporation in a situation of spectacular business success based on a well-designed business and an effectively implementedinnovative business project.,What other technological improvements, innovative organizational, technical and IT solutions will be developed in the future based on the development of the above-mentioned factors?,Will the development of data mining technology, machine learning, artificial intelligence,Big Data data analysis, etc. develop new branches of the knowledge-based economy or only make use of these technologies in already existing branches, sectors of currentlydeveloping economies?,,In view of the above, I am asking you: What are the important issues for you related to the collection and processing of large information sets inBig Data database systems?,,Please reply. I invite you to the discussion","Safeguarding Big Data Systems against possible intrusive information sabotage is , at least to me, the most significant requirement. In other words, security and confidentiality are top priority requirements. | The role of Big Data technology in the development of online data analytics tools used in scientific research and business applicationsThese tools include Google Analytics. However, in addition to this type of the most popular tools created by the largest group of Internet information and marketing services for specialist research, other data analytics tools obtained from the Internet are also used. These specialist studies include sentiment analysis conducted on data obtained from the Internet and collected in Big Data database systems, created and developed by online technology and marketing companies.I invite you to the discussion | Integrity constraints checking & query optimization.  | Are there currently developed risk management instruments and models for obtaining, archiving, analyzing and processing data in Big Data systems?In recent years, the field of research and business applications in the field of obtaining, archiving, analyzing and processing data in Big Data database systems has been developing strongly.In many companies, especially in large corporations, integrated risk management systems are built and improved.Integrated risk management systems combine risk management processes in various areas of a company, institution or other organization.One of the areas of risk management, the importance of which in many companies is growing, is risk management in the area of ??obtaining, archiving, analyzing and processing data in Big Data database systems.In view of the above, I am asking you: Are the risk management instruments and models for the acquisition, archiving, analysis and processing of data in Big Data systems already being developed?Are you already familiar with examples of this type of systems with risk management risk, which concern the acquisition, archiving, analysis and processing of data in Big Data systems?Please reply | What kind of research dominate in the analysis of data collected in Big Data database systems?First of all, as part of the processing of information collected in the Big Data database systems, the sentiment analysis is used very frequently during analytical processes conducted for the needs of scientific research. Sentiment analysis allows you to get an answer to the question, what is, for example, recognizability, what is the awareness, opinion on a specific topic among users of specific Internet portals, websites containing comments from Internet users, and social media portals.I invite you to the discussion | Will future Big Data database systems supported by artificial intelligence be used in precise forecasting in order to verify futurological projections?Currently, it is difficult to define this type of analytic problem. The key issue is forecasting future global problems. It is necessary to collect additional analytical data over the next years, and perhaps in the 21st century, in huge Big Data database systems supported by another generation of artificial intelligence, it will be possible to predict what may happen to the planet Earth in the future.In view of the above, the current question is: Will future Big Data database systems supported by artificial intelligence be used in precise forecasting for the verification of futurological projections?Please, answer, comments. I invite you to the discussion. | Will it be possible to precisely predict the future of the planet Earth in the next 1000 years with the help of the analysis of large data sets in Big Data database systems?Currently, it is difficult to define this type of analytic problem. The key issue is forecasting future global problems. It is necessary to collect additional analytical data over the next years and perhaps in about 100 years in huge Big Data database systems supported by another generation of artificial intelligence, it will be possible to forecast what can happen to the planet Earth in the next 1000 years.In view of the above, the current question is: Will I be able to precisely forecast in the 21st century what will be the future of planet Earth in the next 1000 years?Please, answer, comments. I invite you to the discussion. | What will be the roll of countries like Chile in Data Science Development? Place where are located high tech big telescope facilities | Good envision. What is likely the next generation of Artificail Intelligence to be in addition to current cababilities of learning, predication, analytics ? | The issues of the use of information contained in Big Data database systems for the purposes of conducting Business Intelligence analyzes are described in the publications:https://www.researchgate.net/publication/323244120_The_Big_Data_technologies_as_an_important_factor_of_electronic_data_processing_and_the_development_of_computerized_analytical_platforms_Business_Intelligencehttps://www.researchgate.net/publication/327035102_The_Technological_Solutions_Big_Data_and_the_Importance_of_Business_Analysis_According_to_the_Business_Intelligence_FormulaI invite you to discussion and cooperation. Greetings",True,2025-01-20 01:04:23.522749,2025-01-20 01:04:23.522749,4bd0c214d68711ef89b40c9a3cb15cde
What do you think about the security of information processing in Big Data database systems?,https://www.researchgate.net/post/What-do-you-think-about-the-security-of-information-processing-in-Big-Data-database-systems?_sg=uTcuW4tdi-8xJBMoQMdlvPb0No7K3-GY1IykAbI1eDwhZIbE-sjP7lFTHaCHOSdZSe9iaegF6DqQLdo,2019-02-01 00:00:00,"Considering the specifics of the increasingly commonIT systemsandcomputerized advanced data processingin Internet information systems, connected to theinternet database systems, data processing in thecloud, the increasingly common use of the Internet of Things etc., the following question arises:,What do you think about the security of information processing inBig Datadatabase systems?,,Please reply,,Best wishes","In the context of the above considerations, the following question is also current:How should Big Data database systems be protected against the activities of cybercriminals?Currently, various data security tools are used in Big Data database systems. The basic principle is the parallel use of several types of IT security and compliance with specific procedures for analyzing and securing systems against potential materialization of operational risks, including technical risks associated with used computer hardware and specific database technologies and personnel risks associated with employees who support these systems.The key issue is also whether built database systems are directly connected to the Internet online or are not permanently connected to the Internet and certain data from the Internet are added from time to time to Big Data databases after their analysis by anti-virus software, detecting malware worms, such as keyloggers and other malicious software created by cybercriminals and used to steal information from database systems of data warehouses and Big Data.In a situation when Big Data database systems or other systems where important information is collected are connected to the Internet online, then the information sent should be encrypted, and system gateways connecting the Big Data database with the Internet should be equipped with a good firewall and other filtering security incoming information. If the employees operating the Big Data database system use certain e-mailboxes, they should be only company mailboxes and verified from the security side of data transfer on the Internet. The company should have strict security procedures for using e-mail boxes, because in recent years via e-mails cybercriminals have sent ransomware programs hidden in e-mail attachments, used to encrypt hard disks used in company and server databases.Do you agree with me on the above matter?In the context of the above issues, I am asking you the following question:How should Big Data database systems be protected against the activities of cybercriminals? What types of programs and systems for securing Big Data databases against cybercrime are currently used? What other types of security instruments for Big Data database systems are currently used?Please replyI invite you to the discussionThank you very muchBest wishes | Hi DariuzsI think that the big issue of cibersegurity in the context of Big Data, is the protection of personal data and the transfer's information protocols. However, the open data trend and the interrelationship between structured, semistructured and unstructured data sources could be a big challenge to solve yet.  | If end2end communications are not cryptographically hardened, with each IoT device having its own managed private/public key pair; there will always be issues surrounding the transportation of information from agent to agent.  | Big data database & cloud systems enable governments to access data on an unprecedented basis.  And they are doing this with great enthusiasm.  Refer US Patriot Act, US Foreign Account Tax Compliance Act, OECD Common Reporting Standard and Australia is following up with similar legislation.  It has the potential to become an Orwellian nightmare. |  1. A big Data is a huge data as structure or unstructured you can secure this data in the role of the Organization.2. Cloud is a system or network computing that allow as many of users to access in daily bases. you can't secure cloud due into many users will access into the system. This is users might be one of them a hacker to attack the system. 3. Big data you can change the security access through an organization lead into A strong security. | In the context of the above considerations, the following question is also current:How should Big Data database systems be protected against the activities of cybercriminals?Currently, various data security tools are used in Big Data database systems. The basic principle is the parallel use of several types of IT security and compliance with specific procedures for analyzing and securing systems against potential materialization of operational risks, including technical risks associated with used computer hardware and specific database technologies and personnel risks associated with employees who support these systems.The key issue is also whether built database systems are directly connected to the Internet online or are not permanently connected to the Internet and certain data from the Internet are added from time to time to Big Data databases after their analysis by anti-virus software, detecting malware worms, such as keyloggers and other malicious software created by cybercriminals and used to steal information from database systems of data warehouses and Big Data.In a situation when Big Data database systems or other systems where important information is collected are connected to the Internet online, then the information sent should be encrypted, and system gateways connecting the Big Data database with the Internet should be equipped with a good firewall and other filtering security incoming information. If the employees operating the Big Data database system use certain e-mailboxes, they should be only company mailboxes and verified from the security side of data transfer on the Internet. The company should have strict security procedures for using e-mail boxes, because in recent years via e-mails cybercriminals have sent ransomware programs hidden in e-mail attachments, used to encrypt hard disks used in company and server databases.Do you agree with me on the above matter?In the context of the above issues, I am asking you the following question:How should Big Data database systems be protected against the activities of cybercriminals? What types of programs and systems for securing Big Data databases against cybercrime are currently used? What other types of security instruments for Big Data database systems are currently used?Please replyI invite you to the discussionThank you very muchBest wishes | Dear León Darío Parra Bernal, Robin Renwick, Christopher C Kelly, Wathik Almayali,     Thank you very much for the answers to the question: What do you think about the security of information processing in Big Data database systems? 
Thank you for the information provided and the link to interesting data in the above-mentioned issues. Thank you very much for participating in this discussion and for providing inspiring and informative responses. You described the problem very well. I fully agree with your opinion on this topic. In view of the above, in my opinion, the importance of the issue has been growing in recent years the security of information processing in Big Data database systems.
Thank you very much and best regards,

Have a nice day,
Dariusz Prokopowicz
  | The risk could be in tow form - one you already have mentioned is Security, a vital risk - needs to addressed by collective efforts on a war footing.Secondly, the size of data itself, how integration takes place among hardware, software, latest internet serervice providers, cloud, etc. across the globe is also a risk. | Dear Sunil B. Kapadia, 
Thank you very much for your response. Thank you for confirming my theses on this issue. I am very glad that the discussion on this important topic is developing.
Thank you very much and best regards,

Have a nice day,
Dariusz Prokopowicz
 | you can use block chain technology for securing big data.for that you have to use decentralize approach. Databases uses centralize approach to store data.",True,2025-01-20 01:04:23.574720,2025-01-20 01:04:23.574720,4bd0c214d68711ef89b40c9a3cb15cde
How does a Microsoft SQL server store data logically?,https://www.researchgate.net/post/How-does-a-Microsoft-SQL-server-store-data-logically?_sg=5wjYOqGVwEyP8umfFFUvmiPzfviOQVY_UZnZgZXCo560Q4WP0Kw5TjCF-BYaLs4At5uoRmy5txNel6s,2014-01-01 00:00:00,"An Oracle server stores data logically in Database->Tablespace->Segment->Extent->Block.,,I want to compare Oracle servers with MS SQL servers in terms of the logical storage of  data in the database.,","I agree with Josef. Your question is not clear...Hope this helps..SQL Server""The disk space allocated to a data file (.mdf or .ndf) in a database is logically divided into pages numbered contiguously from 0 to n. Disk I/O operations are performed at the page level. That is, SQL Server reads or writes whole data pages.""http://technet.microsoft.com/en-us/library/ms190969%28v=sql.105%29.aspx | Generally It stores data as files that each file has several records in binary format. How this files store in disk , depends on file organization that DBMS uses . For example sequential, hash and so on .",False,2025-01-20 01:04:23.609536,2025-01-20 01:04:23.609536,4bd0c214d68711ef89b40c9a3cb15cde
What is the best way to physically distribute relational database tables across multiple sites?,https://www.researchgate.net/post/What-is-the-best-way-to-physically-distribute-relational-database-tables-across-multiple-sites?_sg=C_OkPpokO_ZsRSrrCfSMKbykA7nkFgHtD1DfzsSCO0fLBfqJxK1rm8mE1cbs4wigFFr-le5-FVFp9EA,2014-03-01 00:00:00,"I need to distribute some big tables across multiple nodes and want to preserve global schema. Is there a general purpose middleware to handle the data? Sharding/fragmentation? I would also be glad to know if is it possible in MariaDB or FirebirdSQL?,",,False,2025-01-20 01:04:23.630949,2025-01-20 01:04:23.630949,4bd0c214d68711ef89b40c9a3cb15cde
African face data base for face matching? ,https://www.researchgate.net/post/African_face_data_base_for_face_matching?_sg=PJpjFoBpM8ztRQQ6JcRehGkzY5rIploV3s7VNLkdMAI-rudYq8xGOvCDnTIRacmVCb0YcdJMfmVEzZU,2022-09-01 00:00:00,"Please can someone help me find out how to download the CASIA African face data base or suggest another method of finding African faces for a face matching study. I need around 90 faces (in different conditions) half of which are matches and half are non-matches with varied difficulty. (Like the good, the bad and the ugly but for African ethnicity).","Dear Georgia Stevenson ,Face recognition is a popular and well-studied area with wide applications in our society. However, racial bias had been proven to be inherent in most State Of The Art (SOTA) face recognition systems. Many investigative studies on face recognition algorithms have reported higher false positive rates of African subjects cohorts than the other cohorts. Lack of large-scale African face image databases in public domain is one of the main restrictions in studying the racial bias problem of face recognition.Preprint CASIA-Face-Africa: A Large-scale African Face Image Database Regards,Shafagat | In my opinion you have to propose artificial solution for case generation as there could be the lack of amount of input data for possible neural network to be trained",False,2025-01-20 01:04:23.654060,2025-01-20 01:04:23.654060,4bd0c214d68711ef89b40c9a3cb15cde
What are the impacts on organisations when database management systems are implemented?,https://www.researchgate.net/post/What-are-the-impacts-on-organisations-when-database-management-systems-are-implemented?_sg=R5c5dqnLJXNAYXDDRla8OlbZgWNUcEno9lgpN990TI8szN4i1FkrIC4aUak9_C3fvs26t_NDe_zgQik,2013-09-01 00:00:00,"I'm trying to find out some information/journal articles on the impacts of implementing a database management system or implementing databases into organisations and how they can help. If someone could guide me in the right direction please that would be great.,","Well, I am not quite sure what the purpose of that database is supposed to be. Is it ment to hold customer information, should it contain your products ond so on. There is a lot to do with a database and depending on it's purpose the impact will most certainly change. | The database will be used for many purposes like customer details, product details, and so on i want to find journal articles that will help me explain if implementing databases is good, bad or not helpful at all | DBMS are very useful since they have mechanism for transaction management,, concurr ency control, reduction of data redundancy, ease of data access and sharing etc | ""Implementing databases into organizations"" assuming you were asking about computerizing organizational infrastructure impact on various functions ?  Key here are the business rules i.e: Goals, interactions of different users, impact metrics personnel awareness of technology, training requirements, budgets and justification of utilizing technologies over the traditional management. Details are disparate depending on the sector i.e: shopping center to a university, hospital... Try looking to business, management journals. | Perhaps you are looking for information regarding Return on Investment (ROI) to guide a proposal to develop or implement DBMS? ROI estimates should include both tangible financial costs and returns and intangible costs and benefits. As mentioned by Venkateswara above, this really does depend on the sector you are in and the type of system and purpose of the system. ROI seems to be much more easily measured in commercial and financial sectors, but much more difficult to evaluate eg in the health sector, where there is still debate about the benefits of HIT. The benefits derived from a database system (especially if this is not also part of an operational/transactional system) will also depend on the ability to use the stored data afterwards, so benefit can be confounded by poor management and use after implementation. Try looking up ROI for information systems in the relevant business area.",False,2025-01-20 01:04:23.674308,2025-01-20 01:04:23.674308,4bd0c214d68711ef89b40c9a3cb15cde
How to use one hashing bloom filters to detect intrusion in a database management system?,https://www.researchgate.net/post/How-to-use-one-hashing-bloom-filters-to-detect-intrusion-in-a-database-management-system?_sg=vpq6k8QuXZcOlL03eYiIcFoBcfofss2tauRy4KrMpSG__idv0SrQKuO-6SD2sVdO9aB2jXgceUnX4-w,2016-04-01 00:00:00,how to use one hashing bloom filters to detect intrusion in a database management system,,False,2025-01-20 01:04:23.695661,2025-01-20 01:04:23.695661,4bd0c214d68711ef89b40c9a3cb15cde
How can I speed up a MySQL database that is controlled via PHP?,https://www.researchgate.net/post/How_can_I_speed_up_a_MySQL_database_that_is_controlled_via_PHP?_sg=NbKuDu0ykNMfQFSkpkfLZRaR256Lt8q7Lp2roH-K1IYh7B9BJkzk4TZzUotznBXsvvnXRC9Xm6TgYtI,2014-01-01 00:00:00,"The database needs to handle large scale data (12 Mio entries at a time).,","MySQL is controlled by it self, as you know its a DBMS. PHP is just used to retrieve data from MySQL database. Therefore, I think you should look for the MySQL DBMS optimization.What type of data it is? What do you mean by processing 12M data at a time? If your database has 12M entries and you want to update and retrieve data, then you need to improve your searching algorithm in your PHP script.  However, this will improve the performance of the program, not the MySQL database.These are my 2 cents.Good luck,Sarves | MySQL is controlled by it self, as you know its a DBMS. PHP is just used to retrieve data from MySQL database. Therefore, I think you should look for the MySQL DBMS optimization.What type of data it is? What do you mean by processing 12M data at a time? If your database has 12M entries and you want to update and retrieve data, then you need to improve your searching algorithm in your PHP script.  However, this will improve the performance of the program, not the MySQL database.These are my 2 cents.Good luck,Sarves | Another possibility is to look at concurrent opening connection from PHP, it could affect the performance as well. | You can try to use memcached"" memcached is a high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load. ""http://www.php.net/manual/en/intro.memcached.php | You could also trying setting up indexs in your database. If you are using queries that require comparing columns setting up an index will tell the database how to best organize the data to make the query go much faster. For example:  select * from my_table where name like ""Bob""; Will go significantly faster if the column my_table.name is indexed. | First of all, you could try to optimize your database schema by adding appropriate indices (indexes) on fields frequently referenced in clauses or sort and group options in your queries. You can also try to reorganize your tables so that data used for filtering is separated from data being selected. You can achieve this with database model normalization. If you use textual filtering in your queries, such as using the LIKE operator on many fields, you might want to use FULL TEXT index as well.There are many ways to sped up the database. | Better use store procedure,write your full operating in sql & just call it from php | I'm working with atoms positions, thats 90 milions results. To speed up I made new tables with results from the first table, so when came a new request it first look at the small table and if cant find, then look at the big table.You could also divide that big database in many small tables so you may open a thread to look at each of then. So you will get different CPU and diffferent HD working at the same time.",False,2025-01-20 01:04:23.713395,2025-01-20 01:04:23.713395,4bd0c214d68711ef89b40c9a3cb15cde
"Suppose a database schedule S involves transactions T1,........,Tn.If S is serializable then which ordering is guranteed to give a serial schedule ?",https://www.researchgate.net/post/Suppose-a-database-schedule-S-involves-transactions-T1-TnIf-S-is-serializable-then-which-ordering-is-guranteed-to-give-a-serial-schedule?_sg=rl6IfW-uob2n_iQZ7qXW5m4Z7liahqZW94vH70ckJgdEtCk3ycMsSw0fQk4p3oVnbf67qLbWg6_1ud4,2016-02-01 00:00:00,"Suppose a database schedule SS involves transactions T1,........,Tn. Construct the precedence graph of S with vertices representing the transactions and edges representing the conflicts.If S is serializable, which one of the following orderings of the vertices of the precedence graph is guaranteed to yield a serial schedule?,A). Topological order,B). Depth-first order,C). Breadth- first order,D). Ascending order of the transaction indices.,what is the issue with option C and D ?",,False,2025-01-20 01:04:23.740994,2025-01-20 01:04:23.740994,4bd0c214d68711ef89b40c9a3cb15cde
What are the difference between a relational database and an object oriented database?,https://www.researchgate.net/post/Whatare-the-difference-between-a-relational-database-and-an-object-oriented-database?_sg=woZygfyZtt2n3YbQDD8JbZznEfZU9iCoJOVQ6chiY6lkobTo_9l4E6-LxLFNpNf1nap38ayMu0dHe0g,2015-01-01 00:00:00,And how do you convert a map from a relational database to an object oriented database?,"The main difference is the underlying paradigm.A relational databases relies on the relational model, on the other hand a object database relies on the OOP.The relational model organizes information in a set of tables each are composed of rows and columns. Each column represents a property and each row represent an entity.In a object oriented database each element resembles a object from the object oriented paradigm.It is reasonable easy to map object into relational databases. For more information about the topic check these links: link1, link2.Do you want to map a object oriented databe into a relational, or just some object from a program?http://www.ibm.com/developerworks/library/ws-mapping-to-rdb/http://www.agiledata.org/essays/mappingObjects.html | The main difference is the underlying paradigm.A relational databases relies on the relational model, on the other hand a object database relies on the OOP.The relational model organizes information in a set of tables each are composed of rows and columns. Each column represents a property and each row represent an entity.In a object oriented database each element resembles a object from the object oriented paradigm.It is reasonable easy to map object into relational databases. For more information about the topic check these links: link1, link2.Do you want to map a object oriented databe into a relational, or just some object from a program?http://www.ibm.com/developerworks/library/ws-mapping-to-rdb/http://www.agiledata.org/essays/mappingObjects.html | These databases can be used in object persistence as well. | in below link find your answerhttp://www.axswave.com/weblibry/relobjdb.htm | Here is something from my class notes in my introductory undergraduate database course. I hope it helps. | 1) Relational database: A database built on the relational model, which organizes data into tables comprising columns and rows. 2)  Object/relational database management systems (ORDBMSs) add new object storage capabilities to the relational systems at the core of modern information systems. By encapsulating methods with data structures, an ORDBMS server can execute complete analytical and data manipulation operations to search and transform multimedia and other complex objects.  https://www.relationaldbdesign.com/database-design/database-design-glossary.php  | You may look at the paper attached  describing the approach for migrating existing Relational DataBases (RDBs) into Object-Relational DataBases (ORDBs).  ",False,2025-01-20 01:04:23.761370,2025-01-20 01:04:23.761370,4bd0c214d68711ef89b40c9a3cb15cde
"In orthogonal range search on point data set, is it possible to compare  results of kd-trees adapted for pointer machine model along with RAM model?",https://www.researchgate.net/post/In-orthogonal-range-search-on-point-data-set-is-it-possible-to-compare-results-of-kd-trees-adapted-for-pointer-machine-model-along-with-RAM-model?_sg=t3WzlOu0oppaZ5M_RaRK9to1d8KTnc52cB6Vd4v1tGk2QMwoY8CO7FTfahugfnHVnWaINO8MNw3RVu0,2016-02-01 00:00:00,"kd-trees introduced by J.L. Bentley, range trees, divided kd-trees etc. belong to a class of kd-tree variants for pointer machine model. However, Bkd-tree is a RAM model based kdtree,  and recent papers on both models are,a. Pointer machine model,www.madalgo.au.dk/~larsen/papers/4ddom.pdf,b. RAM Model,www.madalgo.au.dk/~larsen/papers/orth_revisit.pdf,For comparisons, can kd-trees and its variants falling under pointer machine model of computation be combined with RAM model based kd trees?",Thanks for the response.,False,2025-01-20 01:04:23.790811,2025-01-20 01:04:23.790811,4bd0c214d68711ef89b40c9a3cb15cde
Is it possible to optimize the database for decreasing the   loading time of an website?,https://www.researchgate.net/post/Is-it-possible-to-optimize-the-database-for-decreasing-the-loading-time-of-an-website?_sg=MoVLtm7HR-cdxKSrkqM1kurqJ1HZIpUTUcPGLScNqWKeG25RdtfgAWZEtklHB0pTkCjRGTi_RQoBTyo,2016-02-01 00:00:00,if it is possible in which way we achieve it,"Hello, can you please add more information - on what platform is the database running, type of the database and so on...? | my s.q.l and java | Sure, you should explore:- using indexes in mySQL: http://dev.mysql.com/doc/refman/5.7/en/mysql-indexes.html- selecting an approppriate table type or storage engine: http://www.mysqltutorial.org/understand-mysql-table-types-innodb-myisam.aspx | Hello Landa,If you are much concerned about the latency of loading a website, then you may look into NoSQL Databases like MongoDB. I think recent versions of MySQL supports NoSQL as well. Optimization is involved from the place of application development, by following best practices , deployment - Having Highly Available Clusters with proper load balancing etc. Hope this helps.-V.Srikrishnan",False,2025-01-20 01:04:23.811926,2025-01-20 01:04:23.811926,4bd0c214d68711ef89b40c9a3cb15cde
How do I create a database front end for R?,https://www.researchgate.net/post/How_do_I_create_a_database_front_end_for_R?_sg=6fUs13mu3uP2wDL667r4Ao7R76u8BkTdGiT_lt_Wn8dOKJe23-JLOgKBLHK4ZdKcBaU_dFtRakpCZWA,2015-04-01 00:00:00,"Does anyone have recommendations for a dataentry/database front end for gathering and uploading data to be used in an R analysis?  I am wondering if anyone has designed and used a digital data entry form (e.g., such as could be created in MS Access) AND somehow embedded a link to R to run analyses and open a browser window with Shiny output.  I want to determine if it is possible for people (field biologists) to enter data remotely into data forms and, meanwhile, managers elsewhere can be running the analysis - both generating report output from queries within the database software (such as the nice text reports from MS Access) and graphics & statistics output from R.  I have created components, but it presently requires an individual to enter and check data from paper data sheets, then save data to text for import to R for analysis, then lots of reformatting of R output to make pretty report documents.  I am using Excel, R, and Shiny - but would welcome suggestions for other software combinations that you've used successfully to link data entry forms directly to R (where I run the interactive analysis and visualization) and remove the manual transfer between software packages.","Hi!This is very interesting. The way I see you have 3 different problems that can be addresses separately.1. Dataentry - Use whatever tool to collect data into a database such as MySQL. This doesn't need to use R at all. You can use a tool lilke REDCap for this; also ODK for tablets data collection.2. Data validation/cleaning - Part of this is done by the form implementation on 1. But additional listing for cleaning can be automatized in a central server using a database that has been generated on 1.3. The final analysis - This step could be integrated on 2. But it is a good idea to have a separated analysis with clean data. Here R would connect to the database, bring the data.My answer is one approach. There are for sure many other. Hope it helps. | Hi!This is very interesting. The way I see you have 3 different problems that can be addresses separately.1. Dataentry - Use whatever tool to collect data into a database such as MySQL. This doesn't need to use R at all. You can use a tool lilke REDCap for this; also ODK for tablets data collection.2. Data validation/cleaning - Part of this is done by the form implementation on 1. But additional listing for cleaning can be automatized in a central server using a database that has been generated on 1.3. The final analysis - This step could be integrated on 2. But it is a good idea to have a separated analysis with clean data. Here R would connect to the database, bring the data.My answer is one approach. There are for sure many other. Hope it helps. | Hi ,I would suggest to use REDCAP for Dataentry , which is a good tool for Clinical data research too. This data can be imported to SQL or any other database to do the reporitng.Very efficient way of reporting and analysis and this can be exported to other analaysis tools like SAS too.Bismi. | refer this for some basic tools:\http://www.activedbsoft.com/overview-querytool.html | the opensource Libreoffice is good option:Forms Wizard in LibreOffice Base makes it easy to create forms so any user can enter data in a database. Follow along the Forms Wizard's process.Open LibreOffice.Select Open Existing Database.Select the database from the drop-down (if it is not listed, click the Open An Existing Database File button and find the database on the filesystem).Click Finish. | Ashton - think of it this way...the database is the middleware, you'll need to design the schema. Pick a front-end for data-entry...Redcap, etc...or perhaps IronSpeed if you need more functionality in a mobile front-end. Embed data scrubbing/prep routines as stored procs or even views in the database for presenting to reporting outputs...whether they be R or others. Badda-bing...you'll be peachy :) | It has been awhile since this was asked, but I think it is an important topic as more and more people use R. As mentioned, there are downsides to using an analysis-focused solution (R) for data entry.  If you want to connect R Shiny to any of a variety of databases (MySQL, SQLite, MongoDB), this site is very usefulhttp://shiny.rstudio.com/articles/persistent-data-storage.html#mysql",False,2025-01-20 01:04:23.834100,2025-01-20 01:04:23.834100,4bd0c214d68711ef89b40c9a3cb15cde
Creating a medical database?,https://www.researchgate.net/post/Creating_a_medical_database?_sg=Ya7Pa0KVbJrW0_8sZIfXpAGeTsTW6dq__dOXskpGXWrAg2ISThpWnYBr6r-R0nUTePu4q0NdlyOcsGQ,2016-05-01 00:00:00,"Does anyone have expertise or experience in creating a medical database, intended to collect/store clinical data? Which program would you recommend?,Or do you know of any source for more information?,Many thanks.","This question is too broad, can you provide a little bit more context. How big will the data be? What is the security requirements in terms of securing the data? Who is going to use it and for what purpose?  | Not an expert, but it looks there are many solutions: http://www.capterra.com/clinical-trial-management-software/ | I am the part-author of a medical database used to store records of surgery, consultations, procedures etc. The database has been in successful use (and continual development) for about 15 years. I can put you in touch with the relevant medical staff if required.(Just to clarify, it is an operational application - not designed for capturing mass clinical trials data and doing statistics on it. For such a requirement the answer given above would be more appropriate). | If you are looking to build it yourself, or have someone custom build something, there are many DBMS systems out there. Different ones have different strengths. So, I would echo Eric's answer: The question is too generic. If you can give details someone who has worked with similar data like Peter or myself may be able to give you advice. If you are not sure of the data and analytical requirements for your project, perhaps you should partner with someone at a nearby university with database expertise or a professional database expert if there are funds available. | Dear colleagues, thank you for all your input. They are very useful. I intend to create a clinical database for breast cancer which contains the following aspects:1. Demographics2. Imaging data e.g. findings on mammography, ultrasound, MRI, staging CT and whole body bone scans. 3. Histopathology4. Treatment - surgery, radiotherapy, chemotherapy5. Follow-up - disease free survival, overall survivalThe above are just the main themes, because I can't list everything here. Hope I am clearer with this now. I have been looking at programs such as MySQL, even cloud platforms e.g. Microsoft Azure system. Any comments and suggestions?Thanks again.  | Take a good look at IBM Informix. The Innovator-C Edition is free for any use or purpose (except redistribution - paid support is available for a low cost if needed - but community support is strong) it is feature and resource limited (2GB of memory use & 8GB storage) but none of the limited features are ones you are likely to need. If you maintian the imaging data in flat files with links in the database the storage limit should not be a problem either. It that becomes an issue there are paid Editions that are reasonable priced (well under $40K US) .What you are getting with Informix is an enterprise quality RDBMS with capabilities (as I outlined in an earlier comment) that you would have to use six different database engines to attain but in a single package. Add on performance, reliability, availability, and scaleability (out and up) that is unmatched in the industry.Informix is fully compatible with most development stacks including ANY development stack that can use REST, the MongoDB API, ODBC, JDBC, and two IBM proprietary APIs. Links to the Edition descriptions and features are:http://www.ibm.com/developerworks/data/library/techarticle/dm-0801doe/http://www.informix.com/ | A few other variables are pertinent, e.g. size, budget and scope.  Size:  Are you looking to handle hundreds of patients, or tens of thousands?  Scope:  single institution or multiple?  Also, will this be linked into a system, or are you planning on manual entry and/or small batch uploading?  If you are planning a single institution database that is pretty much stand-alone, you need some flexibility, and resources are constrained, consider creating your database in Microsoft Access. That's our go-to software for single-site projects that need a real database. It's flexible and user-friendly, and developer guidance is readily available on many topics.  The size of database files is limited to 2GB, but as it grows, you can put individual tables in separate databases and link them if needed.  2GB handles lots of clinical data, unless you are trying to store imaging files directly in the db.  I concur in Art Kagel's suggestion that you keep  images out of the db and link them.  | Try Abstract Plus, developed by CDC USA, it is a cancer registry tool, stable and very helpful for single institution application.http://www.cdc.gov/cancer/npcr/tools/registryplus/ap.htm | Thanks a lot Amid. This is very useful.  | it is depend on type of medical image and the purpose of the dataset .... for example MRI image need collaboration with any hospital to got the images.",False,2025-01-20 01:04:23.866321,2025-01-20 01:04:23.866321,4bd0c214d68711ef89b40c9a3cb15cde
How could we start documentation of existing systems?,https://www.researchgate.net/post/How-could-we-start-documentation-of-existing-systems?_sg=xqeH4cCsbWw3R-DnTrvfNCjdynp4efnXxj9w32KktHOro782X1LlLmPslWb0w1-rHkcztWd6lrm-9M8,2014-10-01 00:00:00,"I have asked this question to collect information about documentation in general. And, to specifically know the procedures of documenting existing systems, especially the old systems that didn't have documentation.","Use the MODEM Architeture Description Method and define the Configuration Baselines of your system elements in your Enterprise System Release. Do all this together with the Requirement Profiles for each element. Then you have defined your design of a Capability Package (CP)/P | Para obtener una buena informacion de un sistema viejo existente, se requiere fijar los objetivos de que es lo que queremos con estos datos para transformarlos en informacion util, optima y adecuada, se requiere crear una arquitectura de sistemas que satisfaga las necesidades de los usuarios a diferentes niveles dentro de la organizacion de la empresa, realizando actividades que todo mundo conocemos co, analisis, diseño, construccion, pruebas e implementacion de el sistema o sistemas de informacion. | In addition to the strategy provided by @Per Johannisson, if you look for reverse engineering && source code analysis sources, then there are a lot of work on this and there are some tools. I am unaware of the current progress and the tools I saw 10+ years ago were quite low.level. For example, googling gives https://www.google.com/search?q=reverse+engineering+tools&ie=utf-8&oe=utf-8&aq=t&gws_rd=ssl and https://www.google.com/search?q=reverse+engineering+tools&ie=utf-8&oe=utf-8&aq=t&gws_rd=ssl#q=source+code+analysis+tools. It really depends on your starting position (some document in the wrong format down to only binary code only). | If you are looking for a tool, that is able to document the current state (or to plan a future state) of a information system, then have a look at 3LGM²-Tool ( http://www.3lgm2.de/en/ ).",False,2025-01-20 01:04:23.895857,2025-01-20 01:04:23.895857,4bd0c214d68711ef89b40c9a3cb15cde
How to shrink my database's logfile to a desired size in MS SQL Server 2008 R2?,https://www.researchgate.net/post/How_to_shrink_my_databases_logfile_to_a_desired_size_in_MS_SQL_Server_2008_R2?_sg=mtsvpk9tpEgQIyEe7yLzHX7A-G4k2m9TO6kYsGC-Ye0Qn7aUfp31EswQor64gmgYUNc9aaXPat3np2I,2013-07-01 00:00:00,"I would like to know if there's a way to resize it up to a desired size, or if it is decided by MSSQLS.,,In any case, how to do that without compromising the whole database?,","In database file properties you can set the size of the file after shrinking. | I know this is a fairly late post (4 months later), but it jut came up in my feed.I've just gone through this process for the first time myself and I recommend a good regular maintenance plan.Backup the transaction logs regularly, and then set the desired size of the log file.If you are regularly seeing your log file expand beyond what you expect you may need to modify your maintenance plan by taking more frequent transaction log backups or increasing the desired log file size appropriately.Using DBCC SHRINKFILE is a part of reducing the file size but isn't a cure to the problem of large log files. It will only shrink it by removing free space in the files.Backing up the transaction log will clear it freeing up space in the existing log file allocated space. This will also stop it growing any larger.If you set a very small log file you can expect that it will be auto grown by sql server (depending on the settings you configure for autogrowth) every time you shrink it.It is better to set a realistic log file size initially and manage it.to restore it fully.I hope this helps",False,2025-01-20 01:04:23.915411,2025-01-20 01:04:23.915411,4bd0c214d68711ef89b40c9a3cb15cde
Could someone suggest a few low impact factor (0.5 to 1) biological database journals?,https://www.researchgate.net/post/Could-someone-suggest-a-few-low-impact-factor-05-to-1-biological-database-journals?_sg=k5_uO-q729ofhtuFugtoremfMYW69eYQ1N7CaXQBqFtdIC6k4UIcUU6Ljp2T6f3iufO2BSHYPD1hYsE,2013-10-01 00:00:00,"Searching for a low impact factor database journal for my work.,","Sir,Please visit the following link.http://www.doaj.org/ | galgotias universitgy",False,2025-01-20 01:04:23.937083,2025-01-20 01:04:23.937083,4bd0c214d68711ef89b40c9a3cb15cde
How to split original dataset to training and testing ones?,https://www.researchgate.net/post/How-to-split-original-dataset-to-training-and-testing-ones?_sg=ngKnUtX0HmJLP5DFdH5Ug-v2HqLYJ7o_cy7Vpegj73Ng_mepWPyRlqdG6zAzyjmEZ4H33RTlP1tBJQQ,2016-02-01 00:00:00,"I have an original dataset with 114 instances and I want to know how I can split it into two sets, the first will be for training and the second will be for testing. in literature I find respectively 75% , 25% or 66% , 34% . Can I have a standardized method?,Regads",I am agree with Vani's statement,False,2025-01-20 01:04:23.960239,2025-01-20 01:04:23.960239,4bd0c214d68711ef89b40c9a3cb15cde
Unable to connect to oracle 11g xe from SAS 9.4?,https://www.researchgate.net/post/Unable-to-connect-to-oracle-11g-xe-from-SAS-94?_sg=gBai0-uI4073ibXT_7TqzV3FJW-nQhIu3t8Q2KS5Y68MqxoNksuWutHQyljydc9XcTf0Bx0RAg1azzg,2018-12-01 00:00:00,",Hello everyone,,Please I need your help to correct this error. I had successfully installed oracle database 11g XE edition  and SAS 9.4 version on a system running on windows 10 Enterprise. I was able to create database through sql-plus or oracle sql developer. I have all required SAS components such as SAS\ACCESS  to ORACLE and SAS\ACCESS to ODBC installed.,I had error while trying to connect to database from SAS using,libname myora oracle user='Bakare' password='Agbaman path='XE';,the error message I got is below:,2    libname myora oracle user='Moshood' passoword='Agbaman' path='XE' ;,ERROR: The SAS/ACCESS Interface to ORACLE cannot be loaded. ERROR: Image SASORA   found but not,loadable..,Please make sure Oracle environment is set correctly.,Look in the install/Config doc for additional info for your platform.,Other possible reasons - incomplete Oracle client install, 32/64-bit mismatch between Oracle,client & SAS, incorrect Oracle client version(Oracle client must match the version,picked during post-install process), incompatible sasora for your OS or its attribs,don't permit SAS to load it.,ERROR: Error in the LIBNAME statement.",,False,2025-01-20 01:04:23.982953,2025-01-20 01:04:23.982953,4bd0c214d68711ef89b40c9a3cb15cde
What data base software to manage patient data in multiple sclerosis?,https://www.researchgate.net/post/What_data_base_software_to_manage_patient_data_in_multiple_sclerosis?_sg=i_BsKUDnC9XCcDl7Ur6CzeJ3DzRms56SvT_RaqAgW4a2twNHIv-buSqAEYKxARLGwPPlnlHqB8Z5xuI,2021-08-01 00:00:00,"Hi,,,I am looking for a database type of software to manage data of patients with multiple sclerosis. The data would be entered periodically during an annual follow-up. The software should enable data extraction based on user-defined criteria. Could you please recommed something?","If this is for cost-sensitive use, outside of a larger hospital or clinic, you might evaluate Open MRS (https://openmrs.org). It is free open source software for electronic medical record management where cost and customization are significant considerations. You would likely need an IT professional to tailor it to your needs and maintain it. | EDMUS is also an option.... | Thanks for the suggestions. A friend recommended the redcap project, which looks promising https://www.project-redcap.org/ | many databases available to manage and organize the databases. you can visit github.com repository ",False,2025-01-20 01:04:24.005913,2025-01-20 01:04:24.005913,4bd0c214d68711ef89b40c9a3cb15cde
How to convert a Mysql database to domain ontology?,https://www.researchgate.net/post/How_to_convert_a_Mysql_database_to_domain_ontology?_sg=Jz2jHX5bjr7jwb13FjrZ0phNsYJ9oGVosmNEAgXfbU1oMj2bO7Iwz4U14niFiGvq4xRVmx9JX-N6SLo,2020-10-01 00:00:00,"How to convert a Mysql database to domain ontology?,,Is there any reliable tool that creates concepts, properties, restrictions, etc. ?","Dear Abdul SattarI found an article on this site with the following link: Article Ontology - Based databases for decision support systems Please see if it is useful for you? |  Behnood Farzad  Thanks for your reply. This article is about databases and distributed databases. it is about the modeling of the domain using databases. The authors did not design domain ontology.  | visit this linkread this article https://www.ijstr.org/final-print/oct2013/A-Framework-To-Convert-Relational-Database-To-Ontology-For-Knowledge-Database-In-Semantic-Web.pdf | Adnan Majeed Thanks for your reply. This article only discusses theoretically. I need a real example. Thanks | I work with ontologies for 20 years. So, if there is a straightforward automated tool like this, then I should know about it. But I don't.However, there might be different options for you. For example, if you convert you database to Excel spreadsheets or a number of Comma Separated Value (CSV) files, then you might import those files into an empty ontology with Protege 5.5 and Cellfie plugin. This workflow is not fully automated. So, you need to learn Cellfie specification language and write a Cellfie script, specifying the rules for ""table to ontology"" transformations. | Igor Toujilov Thanks for your reply. This solution seems good and easy. Thanks again. This will help and save time.",False,2025-01-20 01:04:24.027970,2025-01-20 01:04:24.027970,4bd0c214d68711ef89b40c9a3cb15cde
The refernce gene finder website http://fulxie.0fees.us/ is not opening anymore. Has anyone got a alternative site,https://www.researchgate.net/post/The-refernce-gene-finder-website-http-fulxie0feesus-is-not-opening-anymore-Has-anyone-got-a-alternative-site?_sg=OUJMzp5Nk6lV5CVBcWHfUahOVne6sMl6Lf0mha9tXNStQRVPu7e3yntpvHWituv3wLU3BxCU514OkSU,2017-05-01 00:00:00,http://fulxie.0fees.us/?type=referencewebsite is not opening anymore. Has anyone got a alternative site for this online tool.,,False,2025-01-20 01:04:24.053201,2025-01-20 01:04:24.053201,4bd0c214d68711ef89b40c9a3cb15cde
Could someone suggest the names of some of the rice blast susceptibility genes in rice?,https://www.researchgate.net/post/Could_someone_suggest_the_names_of_some_of_the_rice_blast_susceptibility_genes_in_rice?_sg=4kKM3xkHNeXfMk7S5Nz6kD80uU4GtI3tml7zvrs3iRbre5bS1MNEUZj1VmLNIhKwFtZlaZnnDO0fae4,2017-04-01 00:00:00,Could someone suggest the names of some of the rice blast susceptibility genes in rice?,,False,2025-01-20 01:04:24.074267,2025-01-20 01:04:24.074267,4bd0c214d68711ef89b40c9a3cb15cde
Can anyone help me in knowing how to deposit fungal sequences in NCBI database?,https://www.researchgate.net/post/Can-anyone-help-me-in-knowing-how-to-deposit-fungal-sequences-in-NCBI-database?_sg=txZUiAR6wG9wlGhwOt_CocN6aIPRawV8lCpNnaJFL3MxztcpLak3Iah-jyDSHzEIpBN5flddJ8PxCuo,2017-05-01 00:00:00,Deposition of fungal sequences,"Please use the following toolshttps://www.ncbi.nlm.nih.gov/guide/howto/submit-sequence-data/ | Hi, follow this video link https://www.youtube.com/watch?v=OZxxsRm0pP4 | https://www.youtube.com/watch?v=DhYUYJSm2mQ | 70Hi ReshmaYou can find some useful references on attachment 1https://www.ncbi.nlm.nih.gov/genbank/submit | 2https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3379888/ | 3https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0024940 | 4https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0000059 | 5https://books.google.com/books?isbn=052156784X | 6https://nature.berkeley.edu/brunslab/mycorrhizal/papers/tutorial.doc | 7https://genesdev.cshlp.org/site/misc/ifora_weblinks.xhtml",True,2025-01-20 01:04:24.093424,2025-01-20 01:04:24.093424,4bd0c214d68711ef89b40c9a3cb15cde
How to build a new HMMs from a database (say NCBI)?,https://www.researchgate.net/post/How_to_build_a_new_HMMs_from_a_database_say_NCBI?_sg=oO6MZo9RacUIhAwqEocymgBJtq-0dC8ndMx02rgbPY8Jk8oDO-H2oKuEggNSeRQprgyRUElWkmwxd_U,2020-02-01 00:00:00,"I am new to HMMs and was thinking to build new HMMs based on the NCBI database(which is available to download) or SILVA, so that it can be used by some other program. Can you suggest any tool which can easily serve my purpose?",,False,2025-01-20 01:04:24.115815,2025-01-20 01:04:24.115815,4bd0c214d68711ef89b40c9a3cb15cde
Sub clinical disorder detection,https://www.researchgate.net/post/Sub_clinical_disorder_detection?_sg=bVKWkKb6I5Ghn45b9cQGZPZLllvid62fiVjTeTRNNIoVmtSUNgQCClPdEMnXCErpAwWxSeJZOQrlYyE,2012-11-01 00:00:00,"I need records (Biological records) of some diabetic persons. Is there any database which can give these information and we can trust on it.,",,False,2025-01-20 01:04:24.135200,2025-01-20 01:04:24.135200,4bd0c214d68711ef89b40c9a3cb15cde
Regarding Cambridge Structural Database search with a cell parameter?,https://www.researchgate.net/post/Regarding-Cambridge-Structural-Database-search-with-a-cell-parameter?_sg=9j5tmjMQaJkQoXyqMKg7rMxolYKFaAmWxm2SblFEkj_uYGmP73IOO9ytWxZsC2x0RC8AaveMwXgrb4g,2018-08-01 00:00:00,",Can anyone with CSD access help me with a following cell parameter if any structure exists:,a=11.18Å, α=81.97°, V=2191 Å,,b=12.63 Å, β=71.80°, Triclinic P,c=17.79 Å γ=66.71°,Thanks in advance!","Dear Subhadip,In WebCSD there is no structure featured by those parameters (length tolerance: 1.5, angle tolerance: 2)Regards,Jan | Dear  Jan, Many many thanks, that was a great help. regards, Subhadip@ Jan K. Zareba. | Dear Subhadip Roy,I have searched ICSD for you (no hits) and now concluded my CSD search using the following parameters: cell edges +/-0.2 Å and cell angles (all): 65-84 degrees [a wide net catch more fish!]. There were three hits, but none reallt that close to what you had. Here are the reference codes (with space group and cell parameters a/b/c//alfa/beta/gamma//V within parenthesis), the name of the compund in question, and the original reference plus a DOI link. I hope this helps!NOGRUX (P-1: 11.050/12.520/17.664//71.30/76.38/74.84//2203.2)Fluoro-iodo-dimethyl-(2-(triphenylphosphanylidene)-2-(triphenylphosphonio)ethanedithioato-S,S')-platinum(iv) dichloromethane solvateW.Petz, B.Neumuller, Polyhedron, 2008, 27, 2539.DOI: 10.1016/j.poly.2008.05.003ZAKKUR (P-1: 11.133/12.524/17.725//69.80/79.39/70.92//2184.9)(m3-Tetraphosphido)-bis(h5-1,2,4-tri-t-butyl-cyclopentadienyl)-di-cobalt-pentacarbonyl-molybdenumO.J.Scherer, G.Berg, G.Wolmershauser, Chem. Ber. 1995, 128, 635.DOI: 10.1002/cber.19951280617ZAWQUM (P-1: 11.137/12.470/17.657//77.33/75.90/66.04//2153.2)bis(m-2-(diphenylphosphino)phenyl)-chloro-bis(trifluoromethanesulfonato)-antimony-platinum unknown solvateDi You, F.P.Gabbai, J. Am. Chem. Soc. 2017, 139, 6843.DOI: 10.1021/jacs.7b03287A search without the cell angle search parameter yields an additional 28 P-centered structures.regards,Daniel | Many many thanks Dr. Daniel.Daniel Lundberg ",False,2025-01-20 01:04:24.153846,2025-01-20 01:04:24.153846,4bd0c214d68711ef89b40c9a3cb15cde
CINAHL Database registration?,https://www.researchgate.net/post/CINAHL_Database_registration?_sg=aMMwKduoxgJi-VZHA0BUsdJ-R-x7weiVLsWf6ikEFka92pPyks_G9NH_mFIE3yYM7kvttUV7YQf9D4o,2021-08-01 00:00:00,Hello everyone. How do I register in CINAHL Database? I am hoping someone who knows how to register can help me because I tried many times and could not register and my university did not register with CINAHL Database.,CINHAL database is managed by EBSCO Publishing group. You need to have an EBSCO connect account.https://connect.ebsco.com/s/loginpage?language=en_US&startURL=%2Fs%2F%3Flanguage%3Den_USThe above link can help you to create an account. | Thank you Renju Ravi ,False,2025-01-20 01:04:24.172818,2025-01-20 01:04:24.172818,4bd0c214d68711ef89b40c9a3cb15cde
"When we look up values in a base table using FORMATS, is it possible to use those values in calculations further?",https://www.researchgate.net/post/When_we_look_up_values_in_a_base_table_using_FORMATS_is_it_possible_to_use_those_values_in_calculations_further?_sg=vG1nnGibPDVlNlLwnESTbgYcpoS3OUcJBfj3sJp7pKNQz2FOidvELqX5BHv54bTUyix2Rddqtpwmcp0,2014-06-01 00:00:00,"Combining datasets horizontally in SAS.,","Dear RanjeetaSAS conserves the original data value in the field and shows the formatted value, but you may change the formatted value at any time. If the variable is numeric you may use the original value in any compute. For example if you have a date in format mmddyy10., SAS keeps the number of days between 01/01/1961 and the date. Then you may compute the days between this date and any other as a simple subtraction, or you may get the date from this one plus 100, adding 100 to the original date. The same thing happens with any numeric field in the base. If you want to use the formatted value in any logical expression, you should put its formatted value into the expression using for example the function input in a DATA step.Exampledata _null_;format fecha ddmmyy10.;fecha=mdy(7,13,1958);if fecha=input(""13/07/1958"",ddmmyy10.) then put ""The DATE of my birthday was detected: "" fecha;else put ""The date was not detected"";hoy=mdy(9,8,2014);dias=hoy-fecha;put ""Today I am "" dias "" days old"";run; | Dear Guillermo and Vinay,Thanks a lot for your answer. I really appreciate the help.",False,2025-01-20 01:04:24.192502,2025-01-20 01:04:24.192502,4bd0c214d68711ef89b40c9a3cb15cde
"I can't find a mRNA seq in NCBI database, how can I find it otherwise?",https://www.researchgate.net/post/I_cant_find_a_mRNA_seq_in_NCBI_database_how_can_I_find_it_otherwise?_sg=vNbhOZ30zJGriLck_9FWubAWIbN7vVo5e8VJIf4Z_XwlLS69brGqo4TzYPw2aYoCrV6zRNWVFM8tdIw,2018-11-01 00:00:00,"I am willing to design primers for my differentially expressed genes, however, although I can find gene accession number but I cannot find its mRNA seq in NCBI. Where can I find them?",Go to the FASTA Sequence linkClick send to the button where located in the top right corner. Click coding Sequence and create File.Hope this will help you | Did you try in this way? see below link:https://www.ncbi.nlm.nih.gov/tools/sviewer/mrnaproteindata/ | Go to the FASTA Sequence linkClick send to the button where located in the top right corner. Click coding Sequence and create File.Hope this will help you |  follow ,False,2025-01-20 01:04:24.213897,2025-01-20 01:04:24.213897,4bd0c214d68711ef89b40c9a3cb15cde
Why does close reinsertion perform better than far reinsertion in R*-trees?,https://www.researchgate.net/post/Why-does-close-reinsertion-perform-better-than-far-reinsertion-in-R-trees?_sg=XBhKXJkIg1D84yChglYsmTm1wPVHQmjtGnPcj57CcTAwUaO1skarzFDjc68mm9XPdcuYfCxXHY9riUk,2013-03-01 00:00:00,"Far reinsertion seems to be more intuitive as it removes the entries that are farther, and therefore, have a greater chance of being inserted in some other node.,",,False,2025-01-20 01:04:24.231224,2025-01-20 01:04:24.231224,4bd0c214d68711ef89b40c9a3cb15cde
"Hi, can you recommend any data bases for tracking R&D Spending and Number of Employees for listed U.S. firms?",https://www.researchgate.net/post/Hi-can-you-recommend-any-data-bases-for-tracking-R-D-Spending-and-Number-of-Employees-for-listed-US-firms?_sg=4yWhqKZOriJHrXCFl7ArefDppZmkLwrf9Ohp7uB8bM2fqGbraKrlWTDRGqmCTOLJqVKva-M3Svhmpts,2016-03-01 00:00:00,Do you know of any data bases other than Orbis to find this information?,,False,2025-01-20 01:04:24.250212,2025-01-20 01:04:24.250212,4bd0c214d68711ef89b40c9a3cb15cde
Quality assurance (QA) of papers in review,https://www.researchgate.net/post/Quality_assurance_QA_of_papers_in_review?_sg=qgmbKZs-npaYs5EggvZpUKuu1WDB94X_zH9pjPOGfig0XEOEncwhWy_VKPZGo0aP5Sn_COdigE4DEgA,2022-07-01 00:00:00,"Hi all,,,If we do not have anybody to do quality assurance (QA) of a large number of papers that we get from database searches, say, for example, about a 1000 papers, for a review paper, then what should one do?,,The PRISMA guideline mentions that a second person should review the papers that are included into a review paper (scoping or systematic, etc), but if we do not have anybody to review this large number of papers (for example, 1000 papers) for eligibility, then what should be done? Please help.,,Thanks,Kind Regards,,Zakia Salod,",,False,2025-01-20 01:04:24.268909,2025-01-20 01:04:24.268909,4bd0c214d68711ef89b40c9a3cb15cde
Does anyone know where I can find a sympathic face for my research?,https://www.researchgate.net/post/Does-anyone-know-where-I-can-find-a-sympathic-face-for-my-research?_sg=7mR83vB7_HA3iQzJrNPywhdZcENJJEPb5kAckiTPPdC8gf110RaSI-sp6eZ1g4-s3NH79w02DOKvTdM,2019-03-01 00:00:00,I am looking for a face (male and female) which is proved to be sympathic and is free for use. Does anyone have a suggestion?,,False,2025-01-20 01:04:24.302450,2025-01-20 01:04:24.302450,4bd0c214d68711ef89b40c9a3cb15cde
Best way to find elevation data at a certain point on Earth with respect to time?,https://www.researchgate.net/post/Best_way_to_find_elevation_data_at_a_certain_point_on_Earth_with_respect_to_time?_sg=82b9dFiRSSR9-tmD6t8n49UFPQfjTrCYfu5iedYnfF0LVA9jnEkzQo4zykVYkkVq-tuu2dijBJ_q4fg,2021-06-01 00:00:00,What are the best databases/programs to use if one wishes to find the elevation at a given point on Earth with respect to time? (Say a system that is continuously collecting elevation data over time from which changes in elevation can be detected),"Hi Nicholas Ferreira ,You can try the ALOS PALSAR Digital Elevation Models (DEM). Here is the link where to download the dataset:https://search.asf.alaska.edu/#/Another possibility is to generate the model from InSAR images.Here is a link to a discussion related to the topic of your question:https://www.researchgate.net/post/How-to-use-InSAR-data-for-determining-the-grounds-surface-motionHope this helps. | http://www.irea.cnr.it/en/index.php?option=com_k2&view=item&id=77:differential-synthetic-aperture-radar-interferometry&Itemid=139",False,2025-01-20 01:04:24.324484,2025-01-20 01:04:24.324484,4bd0c214d68711ef89b40c9a3cb15cde
What is the diffrence between a SD and a smart card?,https://www.researchgate.net/post/What-is-the-diffrence-between-a-SD-and-a-smart-card?_sg=caEY25moYLf12OzvxcQQH_Q6BbDXcGZEs2UDuv3M7XSPpU_1oj1-74jvSOAAXqYKwxAE-dg6Ly_gJUw,2012-10-01 00:00:00,"Want to explore file structure of SD card but I can find technical papers on smart cards only.. can anyone help?,",An SD card is a storage device typically used by cameras (de facto standard now). A smart card is an older moniker for a credit or debit card (for example) with a chip. ,False,2025-01-20 01:04:24.346386,2025-01-20 01:04:24.346386,4bd0c214d68711ef89b40c9a3cb15cde
How do I Implement A Central Authentication System?,https://www.researchgate.net/post/How_do_I_Implement_A_Central_Authentication_System?_sg=uWJ1lVbAH1hxYmx-ZCHcquSgZcKnH3zXweqfx_niGfANsNKhOZdho291sT7qIZgSpn5sNV1bfSacFJc,2017-12-01 00:00:00,",I am tasked with responsibility to construct a Central Authentication System on web portals with existing legacy systems that have MySQL as their back-ends. How do i achieve this by constructing or designing a Web SSO where all staff/students in my University login via a single platform with Access Management maintained across this web portals with different MySQL databases. Thank you",,False,2025-01-20 01:04:24.365038,2025-01-20 01:04:24.365038,4bd0c214d68711ef89b40c9a3cb15cde
How do i manage Users Accounts in MySQL database?,https://www.researchgate.net/post/How-do-i-manage-Users-Accounts-in-MySQL-database?_sg=Bl7rEtm6iPlz07zxdAW7kHDM3ZDFpjKUHAllc2XcYglnTSaygIwY7ZJLcpjRvdCoK7I5OfIxXaTz0l8,2017-12-01 00:00:00,How do i manage Users Accounts in MySQL database with their correcting logs activity via phpmyadmin,"Colleague here is what you need.https://docs.phpmyadmin.net/es/latest/privileges.htmlregards. | Thank you distingushed colleague for the documentation, however how do I monitor activity logs for each user created? the provision in phpmyadmin seems only to be ""localhost/phpmyadmin/Status/Query statistics"" which is not tired to any user | Dear For managing each user in your system you should create a log table every time a user enters the system save the activity he/she do in the log table for example if the user add or insert data to a specific table enter these detail to log table then later you can watch the full detail activity each user done in your system | DearYou can do it automatically when having your own web hosted server in Cpanel by referring to Awstats. However, if you manage to use it locally, you may add new field at Table User (for instance IP address), so during login activity, just put $sql = ""insert into UsersTable(UserID, LoggedTime, LoggedIP) values('"".CurrentUserID().""','"".CurrentDateTime ().""','"".CurrentUserIP().""')"";",False,2025-01-20 01:04:24.384625,2025-01-20 01:04:24.384625,4bd0c214d68711ef89b40c9a3cb15cde
What are the methods are used for DB optimization?,https://www.researchgate.net/post/What-are-the-methods-are-used-for-DB-optimization?_sg=s7C_QIKSaSomMraqWhUsoKMSux9hYfXELUS88azCpbqpuCB8wBRRf_o__T2ewgEBYmak9ssgDRBRkfI,2016-02-01 00:00:00,if it is there please mention it.,"Commonly used аrе some procedures for database normalization, in order to ignore several types of anomalies. | Database optimization is very big topic and most of the time database vendor specific. Along with above mentioned links here is really comprehensive explanation about ""How does a relational database work"" http://coding-geek.com/how-databases-work/ that includes a section on ""optimization"".",False,2025-01-20 01:04:24.407213,2025-01-20 01:04:24.407213,4bd0c214d68711ef89b40c9a3cb15cde
Anyone expert in database searching?,https://www.researchgate.net/post/Anyone-expert-in-database-searching?_sg=LxRCzCFU7uFZeGJlC28tbu7JI-t6chbI4-PGxKk-jqw5n_5ngGODmPvuDrYKKcMtMGsTvAhc-gaDigU,2017-12-01 00:00:00,"Hello everyone, Need a bit of help in google scholar, Indmed and Latin LILAC search database.,thank you","Yes. Thank you Zheng. I am trying to search three databases ; IndMed, Google scholar and Latin LILAC. I am not achieving what i want.IndMed says i am using non permitted characters though i am only using the operators mentioned on their instruction page. How to narrow down search on Google Scholar? Do i use OR and AND in it? Do i put in all synonyms (keywords)?In LILIAC do i type in words in spanish or english or both?i am about to conduct a systematic review. thank you,Dr Omar   | Dear Omar, Have a look on this website regarding searching part which is related to Google Scholar https://guides.nyu.edu/googlescholarMake sure for using Punctuation Mark such as brackets specially when you are doing your searching parts for databases Regarding your question of using OR or AND it depends on your searching criteria as Boolean operators  helps you to build your specific part of searching and focusing your included studies that you are going to screen later  | Dear Sami,Thank you for your response. Let's say my topic is on Pneumonia in children under 5 years of age and i am thinking of including ""child"" ""infant"" ""neonate"" in my search strategy. The GS advanced search shows space for  Find articleswith all of the words---------------
with the exact phrase-----------------
with at least one of the words--------------------
without the words-------------------------How should i proceed?thank you,Dr Omar  | Put Pneumonia in the ""all of the words category"", and child infant neonate in the ""at least one of the words"" category. | Thank you very much William",False,2025-01-20 01:04:24.427045,2025-01-20 01:04:24.427045,4bd0c214d68711ef89b40c9a3cb15cde
"Where can I find ""steel value added of all countries"" data?",https://www.researchgate.net/post/Where_can_I_find_steel_value_added_of_all_countries_data?_sg=BFsk6R1oLrAT5JJ_FVAtMdDEqJjByoS7gvhVQnQ2ADIYEUtMEHdSFnEkZIcQ-tqG_ZI74CODbLhg6t4,2014-04-01 00:00:00,"I'd like to have it for my article.,","Hi shima, I think in this web page you could find some info regarding to steels, production, etchttp://www.worldsteel.org/statistics/statistics-archive.html",False,2025-01-20 01:04:24.449056,2025-01-20 01:04:24.449056,4bd0c214d68711ef89b40c9a3cb15cde
How to match genes from one organism with another diferent kind of organism (database search)?,https://www.researchgate.net/post/How_to_match_genes_from_one_organism_with_another_different_kind_of_organism_database_search?_sg=SbdAzdfdV_wFzCxnLUYeiyTzvauRulRahq9-mBQOWgKJaBSZIvIxKjwEL_mO9lTaTzZPdWjx-mkv4Bg,2023-05-01 00:00:00,We believe that 4 protein found in a piroplasmid are also found in a Dermocentor tick. How do you search for this kind of match in the databases?,,False,2025-01-20 01:04:24.470122,2025-01-20 01:04:24.470122,4bd0c214d68711ef89b40c9a3cb15cde
What software can I use to compare two annotated genomes downloaded from NCBI database?,https://www.researchgate.net/post/What_software_can_I_use_to_compare_two_annotated_genomes_downloaded_from_NCBI_database?_sg=ci26yFUl_PzodikuXbQYDa-Jyw2v7m2UWgW-Fqy_JXCNAkRSn8iIHlkPqESdpL9-3PWwsygGzA2m9DQ,2024-04-01 00:00:00,Which software to compare two genomes,Article Comparative Genomic Analysis Using the UCSC Genome Browser  I remembered UCSC has tools for different purposes for that?  ,False,2025-01-20 01:04:24.493190,2025-01-20 01:04:24.493190,4bd0c214d68711ef89b40c9a3cb15cde
Can anyone recomend me an updated protein-ubiquitination database?,https://www.researchgate.net/post/Can_anyone_recomend_me_an_updated_protein-ubiquitination_database?_sg=90teknBtlGS0SbJLvJK8pi6qa01IO1eiyICyou_u4NFvcFe8MZfhLCKd_daYiclfc4knD4whjVBl9a8,2022-12-01 00:00:00,"I want access to a database where proteins can be searched and the presence of ubiquitination and other parameters (ub link, mono/poly/branched ubi...)","There are several databases that provide information about protein ubiquitination. Some options include:UbiProt: This is a comprehensive database of ubiquitination sites and ubiquitin chain topologies in the human proteome. It contains data from multiple sources, including literature, high-throughput experiments, and manual curation.UbiSite: This database is specifically focused on ubiquitination sites and their functional consequences. It provides information about the type and position of ubiquitination sites, as well as the context in which they occur.UniProt: This is a well-known database of protein information, including information about ubiquitination. It provides data about ubiquitination sites and other post-translational modifications, as well as information about the protein's function and structure.UbiDb: This database provides information about ubiquitin-specific proteases and deubiquitinating enzymes, as well as their substrates and regulatory mechanisms. It also includes information about ubiquitin-like proteins and their functions. | see this linkhttp://uucd.biocuckoo.org/ ",False,2025-01-20 01:04:24.516112,2025-01-20 01:04:24.516112,4bd0c214d68711ef89b40c9a3cb15cde
✨Free Sample Questions for the Oracle 1Z0-076 Exam Prepare Effectively,https://www.researchgate.net/post/Free_Sample_Questions_for_the_Oracle_1Z0-076_Exam_Prepare_Effectively?_sg=_aZeQDQm0llMW7n5mMbuQ96RJ03AXiPUInH0wpHnV7bqyzDB8eikQmP4B4u7vBrvEK7D-EKh6cmkFfk,2024-10-01 00:00:00,"The Oracle 1Z0-076 certification exam validates professional skills and knowledge. Passing the 1Z0-076 Exam leads to becoming a certified member of enhancing career prospects. Are you feeling stressed about the Oracle Database 19c: Data Guard Administration Exam? Relax, CertsTime has your back! Our expertly crafted, realisticOracle 1Z0-076 Practice Questionsare designed to elevate your confidence and ensure you are fully prepared for test day. The Oracle Database 19c: Data Guard Administration 1Z0-076 certification exam validates the knowledge and skills of successful applicants. You can further your career in the fiercely competitive industry and become a certified member of Oracle Database by getting 1Z0-076 Exam Certification. Additionally, after completing the exam, successful applicants for the practice test exam can benefit from several additional features. Benefits of the 1Z0-076 exam include updated knowledge, new professional prospects, networking, credibility, and job responsibilities; demonstrated abilities; instant pay increases; and early promotion.,Download Oracle 1Z0-076 Exam Question 2024 From Here :,https://www.certstime.com/cheat-sheet-1z0-076-dumps",,False,2025-01-20 01:04:24.560538,2025-01-20 01:04:24.560538,4bd0c214d68711ef89b40c9a3cb15cde
Define a checkpoint in a database management system ?,https://www.researchgate.net/post/Define_a_checkpoint_in_a_database_management_system?_sg=7s2yrbnQNYfy3LzbZt9WQsNcPyIsie-hoi-JS3V4fvwDGaZvSLoCyT0qfP9JH_GBn4JmMvxPzf31VFs,2023-05-01 00:00:00,",,","Dear Doctor""A checkpoint is used for recovery if there is an unexpected shutdown in the database. Checkpoints work on some intervals and write all dirty pages (modified pages) from logs relay to data file from i.e from a buffer to a physical disk. It is also known as the hardening of dirty pages.""",False,2025-01-20 01:04:24.584878,2025-01-20 01:04:24.584878,4bd0c214d68711ef89b40c9a3cb15cde
Which are some approaches for IoT databases?,https://www.researchgate.net/post/Which-are-some-approaches-for-IoT-databases?_sg=efuG_itdqx-VPu-q2RW_wCewmVpEx4qRGZBFMWoXKmzYr-ASL6bz7vEISjB6kpUIQ-i_qtRMqqBQQ4Y,2018-05-01 00:00:00,"Hi,,,I have read that hybrid relational and nonrelational databases are a good approach for IoT applications where real time analytics are needed (correct me if I'm wrong),,Which is your opinion about this and there is some paper or information somewhere where I can read more about this?,,New to databases here, all information is welcome.,,Regards,","Here is my short answer to your short question: Time Series database, if not that, then NoSQL type database. Here is the long answer. It depends. I am sure my peers may have different opinions on this, so I qualify my response as the simple opinions of a DBA who has started to enter the IOT arena from a business point of view, vs. scientific. I present to you a long rant, but you did ask about databases and I am a dba.Closer examination of your requirements will bring you closer to a solution to consider. For example, as a peer previously stated, there are choices of database TYPES - relational, NoSQL and I add, Time Series. Each type has it's own advantages but no one is better than the other, hence your own requirements will lead you. Generally for IOT, you want something lightweight (not much overhead and does not require significant resources), that can accommodate many small transmissions, over and over again, so as to become large by volume. I would start by considering the time series database: https://en.wikipedia.org/wiki/Time_series_database, which is  more process efficient than the traditional relational database. You really do not need relational databases for IOT unless you are going to take advantage of relational specific functionality, as relational databases require you to send data in a stringent (perfect) format to match the record definition in the database. NoSQL databases, do not require you to stick to a predefined or stringent format to insert data. Just send what you have and in it goes. To cross reference the difference between the relational and NoSQL database goes something like this: I send first_name, last_name, address and zipcode into a NoSQL database. In it goes...The next record I send to the NoSQL database only has first_name and last_name. In it goes to. Try the same thing with a relational database and the second record will be rejected as the data is incomplete. The trade off is, in the NoSQL database, the second record will never show up on a query (search) using address.So I close with a few requirement questions, which I hope can bring you closer to what you are seeking:1. What kind of data are you collecting? Is it vital to your business? 2. How important is each piece of data you collect? It's it monitoring life-support or simply the temperature of a pair of sneakers on a pallet? 3. Which component does the actual data interpretation? Asking if the database is to make sense of the data or simply serve as a collection repository for an application program to extract the data for processing. 4. What happens if you lose the database? Can you easily recover or do you have to start over. Terms such as High-availability and Disaster recovery are common considerations for database processing. A single silo of data is a single point of failure. Whether or not your choice of databases offers redundancy should at least be considered. 4. How often do you send the data? Who knows, if the data is collected and bundled before sending to a database in a burst, then maybe a  relational database has value,  then again...--Best of luck,John | i think NoSQL is better for big data storage, so i would recommend it for big sensor networkshttps://www.tutorialspoint.com/mongodb/index.htmHere is an absolute beginner resource to MongoDB, worth reading if you have no prior knowledge of it. | Hi,For IoT, you may also have a look at InfluxDB and related stack: https://www.influxdata.com/time-series-platform/influxdb/ | Blockchain also plays an important role in a range of IoT application scenarios. You may wish to begin experimenting with BigchainDB (or similar) to learn more about the core concepts: https://www.bigchaindb.com/ | Here is my short answer to your short question: Time Series database, if not that, then NoSQL type database. Here is the long answer. It depends. I am sure my peers may have different opinions on this, so I qualify my response as the simple opinions of a DBA who has started to enter the IOT arena from a business point of view, vs. scientific. I present to you a long rant, but you did ask about databases and I am a dba.Closer examination of your requirements will bring you closer to a solution to consider. For example, as a peer previously stated, there are choices of database TYPES - relational, NoSQL and I add, Time Series. Each type has it's own advantages but no one is better than the other, hence your own requirements will lead you. Generally for IOT, you want something lightweight (not much overhead and does not require significant resources), that can accommodate many small transmissions, over and over again, so as to become large by volume. I would start by considering the time series database: https://en.wikipedia.org/wiki/Time_series_database, which is  more process efficient than the traditional relational database. You really do not need relational databases for IOT unless you are going to take advantage of relational specific functionality, as relational databases require you to send data in a stringent (perfect) format to match the record definition in the database. NoSQL databases, do not require you to stick to a predefined or stringent format to insert data. Just send what you have and in it goes. To cross reference the difference between the relational and NoSQL database goes something like this: I send first_name, last_name, address and zipcode into a NoSQL database. In it goes...The next record I send to the NoSQL database only has first_name and last_name. In it goes to. Try the same thing with a relational database and the second record will be rejected as the data is incomplete. The trade off is, in the NoSQL database, the second record will never show up on a query (search) using address.So I close with a few requirement questions, which I hope can bring you closer to what you are seeking:1. What kind of data are you collecting? Is it vital to your business? 2. How important is each piece of data you collect? It's it monitoring life-support or simply the temperature of a pair of sneakers on a pallet? 3. Which component does the actual data interpretation? Asking if the database is to make sense of the data or simply serve as a collection repository for an application program to extract the data for processing. 4. What happens if you lose the database? Can you easily recover or do you have to start over. Terms such as High-availability and Disaster recovery are common considerations for database processing. A single silo of data is a single point of failure. Whether or not your choice of databases offers redundancy should at least be considered. 4. How often do you send the data? Who knows, if the data is collected and bundled before sending to a database in a burst, then maybe a  relational database has value,  then again...--Best of luck,John | I'm in the security business, so you can assume that my opinions are heavily biased. Both MySQL and MongoDB are notoriously insecure, and get hacked daily. I would vigorously oppose their use in any system I was designing.Just for fun, why not design your own in-memory database?https://www.researchgate.net/project/IDaaS-with-secure-data-at-rest/update/5b0360f74cde260d15e01961 | Thanks for the answers, I was reading this:https://www.wirelessdesignmag.com/blog/2015/03/database-management-iot-relational-nosql%E2%80%A6or-bothRegards, | I think the basic question is what kind of data will be collected?  What type of data will be sent, what is the size of individual data, how much data will be sent and stored in a unit of time.  The significance of the collected data will also be important, as was also written by the previous speaker.Answers to these questions, as well as many others, will guide your choice. I am not convinced that it must always be a NoSQL based solution.  Below, in spite of everything, I provide a link to selected open source databases adapted for IoT solutions:https://opensourceforu.com/2017/05/best-open-source-databases-iot-applications/And some more, I think of useful links:https://www.yugabyte.com/solutions/industries/iot/https://www.computerweekly.com/blog/Write-side-up-by-Freeform-Dynamics/Whats-all-the-fuss-about-in-memory-databases-for-IoThttp://www.datacenterjournal.com/industry-outlook-iot-databases/https://www.oracle.com/pl/solutions/internet-of-things/index.html",False,2025-01-20 01:04:24.608623,2025-01-20 01:04:24.608623,4bd0c214d68711ef89b40c9a3cb15cde
What are safe ways to connect to the PostgrQSL Database from Web Maps?,https://www.researchgate.net/post/What-are-safe-ways-to-connect-to-the-PostgrQSL-Database-from-Web-Maps?_sg=uUUejGqePTSmoCA9NGB3xtV5cCQphik02swSNEcn671fartLTL4Wt8-EN_uamRAlwu4TNfyIfao4aM0,2014-12-01 00:00:00,"I want to use PHP to pull data from the PostgreSQL Database into my application. I wanted to know whether this method is secure, if my various users will have to interact with data.","Hi KibuiYo can secure database access in many ways. You can use HTTPS to secure the communitations. Also you can allow access to the database only from the application running on the server whith a low permission role, and the users can access the PHP application using a different credentialYou can find information about PHP database access in [1] and PsotgreSQL in [2]Kind regards[1] http://php.net/manual/en/security.database.php[2] http://www.postgresql.org/docs/7.0/static/security.htm | If your servers are located in the same physical lication on different machines, you can connect them with a fast gigabit network connection and have the connections exclusive, by having those two (or a few) servers in a separate network segment (range). Than, attach another newtork interface to the Web service's server and connect it to the gateway by giving it an address in the public network address range (or, perhaps through a firewalled GW if that is your service's network organization requirement).That way, the DB and WEB server communicate directly and very fast without the latency encryption usually gives), but the DB server is isolated from the public web, so in that sense, data is secure.And the only publicly exposed part is the Web server hosting the PHP application, which is fine, as long as it is secure from Rootkit exploits etc. | Hello Milan Ferik Tair,Thank you very much for this advice.I really like the idea.Let me research more on it.Regards | restful api.",False,2025-01-20 01:04:24.644680,2025-01-20 01:04:24.644680,4bd0c214d68711ef89b40c9a3cb15cde
